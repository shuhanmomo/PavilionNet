{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_c2daYyAAUx"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaJecW2AAVbw"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEVdiJ1MFKJi",
        "outputId": "be6e004e-8319-4e3f-ec41-46c75916476b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Requirement already satisfied: python-utils>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from progressbar2) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>3.10.0.2 in /usr/local/lib/python3.10/dist-packages (from python-utils>=3.0.0->progressbar2) (4.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install progressbar2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slDg01c7Fs2T",
        "outputId": "f733847d-e8e5-4b3a-d74f-2a977ac8e706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn7eEI-wF02S",
        "outputId": "0640905e-7f57-41ec-b5fc-669b2c352c23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trimesh\n",
            "  Downloading trimesh-4.0.0-py3-none-any.whl (687 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/687.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/687.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m686.1/687.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m687.0/687.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from trimesh) (1.23.5)\n",
            "Installing collected packages: trimesh\n",
            "Successfully installed trimesh-4.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install trimesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H6YINJGF5ni",
        "outputId": "10795971-baf5-4363-863d-cab2e4971488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/307.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/307.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZ752ud5GNxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1c6252-9f96-4b07-a9cc-b874c8868113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_scatter-2.1.2%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt21cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_sparse-0.6.18%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.3)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt21cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_cluster-1.6.3%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.11.3)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.23.5)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt21cu118\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-_svlkl61\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-_svlkl61\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 00a1794238e5f4a9b72bcb80bb43d0231271886b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.4.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.4.0-py3-none-any.whl size=1037064 sha256=f3b2367808ab4b82d28c3e9967163f68429fc8176a5b181c2e3be771e445cd53\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ib_iz5el/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbRPiMBAHqHA",
        "outputId": "cc449229-1913-4170-8867-dea2335346c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWI5u4NqIJLR"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown >/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru_GtncvXqn8",
        "outputId": "af6ae984-5fc7-425b-c3f6-f1ed021d35ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyquaternion\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyquaternion) (1.23.5)\n",
            "Installing collected packages: pyquaternion\n",
            "Successfully installed pyquaternion-0.9.9\n"
          ]
        }
      ],
      "source": [
        "!pip install pyquaternion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_t68xEJqz7P",
        "outputId": "c3ce2f5d-4810-474b-b448-5d06b30caf06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymesh\n",
            "  Downloading pymesh-1.0.2.tar.gz (5.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pymesh) (1.23.5)\n",
            "Building wheels for collected packages: pymesh\n",
            "  Building wheel for pymesh (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymesh: filename=pymesh-1.0.2-py3-none-any.whl size=6900 sha256=6796029013ff797d6e0f85a0739b94a90de06a5866033c4b0608b19e89eac57c\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/aa/05/b758da80b5028b4bbf0d0ed86ec9099ca40e195563fd32b7b8\n",
            "Successfully built pymesh\n",
            "Installing collected packages: pymesh\n",
            "Successfully installed pymesh-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pymesh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-gnZmvPAYtB"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEoR9dcZh4tO"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import scipy\n",
        "import sklearn\n",
        "import matplotlib\n",
        "import progressbar\n",
        "import tensorboardX\n",
        "import trimesh\n",
        "import torch\n",
        "import torchvision\n",
        "import ninja\n",
        "import shapely\n",
        "import jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ewLORBbG_jd",
        "outputId": "3ae3e579-29df-47dd-9aac-e4de7564c641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3znw5bNEHZbr",
        "outputId": "5b4c9f5d-e71d-44fc-f20f-a711e8ea07e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory is: /content/drive/MyDrive/MIT Creative Machine Learning/Final Project/structurenet0503\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Set root directory\n",
        "root_dir = '/content/drive/MyDrive/MIT Creative Machine Learning/Final Project/structurenet0503'\n",
        "\n",
        "# Change working directory to root directory\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# Confirm current working directory\n",
        "print(\"Current working directory is:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVUrQiYvY83c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# data_zip = os.path.join(root_dir , \"data/partnetdata/pavilion_hier1009.zip\")\n",
        "# data_dir = os.path.join(root_dir, \"data/partnetdata/pavilion_hier1009\")\n",
        "\n",
        "# if not os.path.exists(data_dir):\n",
        "#     os.makedirs(data_dir)\n",
        "# !unzip -q \"{data_zip}\" -d \"{data_dir}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KiIVgBSAcxJ"
      },
      "source": [
        "## Clone Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWbNRW36CrPo"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/MIT Creative Machine Learning/Final Project/structurenet0503/code')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e8krzlYIo8p"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afs9ikaVJFhB"
      },
      "outputs": [],
      "source": [
        "sys.path.append('./code/cube.pts')\n",
        "sys.path.append('./code/chamfer_distance')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InsXaiYdJ8qT"
      },
      "source": [
        "## Chamfer Distance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn_vbeMXKBs9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from torch.utils.cpp_extension import load\n",
        "cd = load(name=\"cd\",\n",
        "          sources=[\"./code/chamfer_distance/chamfer_distance.cpp\",\n",
        "                   \"./code/chamfer_distance/chamfer_distance.cu\"])\n",
        "\n",
        "class ChamferDistanceFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, xyz1, xyz2):\n",
        "        batchsize, n, _ = xyz1.size()\n",
        "        _, m, _ = xyz2.size()\n",
        "        xyz1 = xyz1.contiguous()\n",
        "        xyz2 = xyz2.contiguous()\n",
        "        dist1 = torch.zeros(batchsize, n)\n",
        "        dist2 = torch.zeros(batchsize, m)\n",
        "\n",
        "        idx1 = torch.zeros(batchsize, n, dtype=torch.int)\n",
        "        idx2 = torch.zeros(batchsize, m, dtype=torch.int)\n",
        "\n",
        "        if not xyz1.is_cuda:\n",
        "            cd.forward(xyz1, xyz2, dist1, dist2, idx1, idx2)\n",
        "        else:\n",
        "            dist1 = dist1.cuda()\n",
        "            dist2 = dist2.cuda()\n",
        "            idx1 = idx1.cuda()\n",
        "            idx2 = idx2.cuda()\n",
        "            cd.forward_cuda(xyz1, xyz2, dist1, dist2, idx1, idx2)\n",
        "\n",
        "        ctx.save_for_backward(xyz1, xyz2, idx1, idx2)\n",
        "\n",
        "        return dist1, dist2\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, graddist1, graddist2):\n",
        "        xyz1, xyz2, idx1, idx2 = ctx.saved_tensors\n",
        "\n",
        "        graddist1 = graddist1.contiguous()\n",
        "        graddist2 = graddist2.contiguous()\n",
        "\n",
        "        gradxyz1 = torch.zeros(xyz1.size())\n",
        "        gradxyz2 = torch.zeros(xyz2.size())\n",
        "\n",
        "        if not graddist1.is_cuda:\n",
        "            cd.backward(xyz1, xyz2, gradxyz1, gradxyz2, graddist1, graddist2, idx1, idx2)\n",
        "        else:\n",
        "            gradxyz1 = gradxyz1.cuda()\n",
        "            gradxyz2 = gradxyz2.cuda()\n",
        "            cd.backward_cuda(xyz1, xyz2, gradxyz1, gradxyz2, graddist1, graddist2, idx1, idx2)\n",
        "\n",
        "        return gradxyz1, gradxyz2\n",
        "\n",
        "\n",
        "class ChamferDistance(torch.nn.Module):\n",
        "    def forward(self, xyz1, xyz2):\n",
        "        return ChamferDistanceFunction.apply(xyz1, xyz2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzAFQRuKJ_xb"
      },
      "source": [
        "## Model Structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTEXmJ3uIvOZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import torch_scatter\n",
        "import compute_sym\n",
        "from utils import linear_assignment, load_pts, transform_pc_batch, get_surface_reweighting_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-d87rGiKt7h"
      },
      "outputs": [],
      "source": [
        "#  generate new 3D models that are structurally consistent with the input data, while also being diverse and plausible.\n",
        "# t takes as input a feature vector x and outputs a sample from a learned distribution over that feature space.\n",
        "class Sampler(nn.Module):\n",
        "\n",
        "    def __init__(self, feature_size, hidden_size, probabilistic=True): #hidden size is the hidden layer num of MLP\n",
        "        super(Sampler, self).__init__()\n",
        "        self.probabilistic = probabilistic # whether the sampling operation is probabilistic (i.e., stochastic) or deterministic.\n",
        "\n",
        "        self.mlp1 = nn.Linear(feature_size, hidden_size)\n",
        "        self.mlp2mu = nn.Linear(hidden_size, feature_size)\n",
        "        self.mlp2var = nn.Linear(hidden_size, feature_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encode = torch.relu(self.mlp1(x))  #generate the hidden representation.\n",
        "        mu = self.mlp2mu(encode)\n",
        "\n",
        "        if self.probabilistic:\n",
        "            logvar = self.mlp2var(encode)\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = torch.randn_like(std)\n",
        "\n",
        "            kld = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
        "\n",
        "            return torch.cat([eps.mul(std).add_(mu), kld], 1)\n",
        "        else:\n",
        "            return mu # a sampled feature vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZOCBw3TNA5P"
      },
      "outputs": [],
      "source": [
        "#  encode a 3D bounding box into a fixed-size feature vector.\n",
        "class BoxEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, feature_size):\n",
        "        super(BoxEncoder, self).__init__()\n",
        "        self.encoder = nn.Linear(10, feature_size)\n",
        "\n",
        "    def forward(self, box_input):\n",
        "        box_vector = torch.relu(self.encoder(box_input))\n",
        "        return box_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og8-RkYch8IF"
      },
      "source": [
        "the GNNChildEncoder class is used to encode the child node features of a tree structure into a single parent node feature vector using a graph neural network (GNN) message-passing algorithm. The parent node feature vector is computed by aggregating information from the child nodes over a specified number of message-passing iterations.\n",
        "\n",
        "The GNN message-passing algorithm updates the hidden feature vectors of the child nodes using information from their neighboring nodes (i.e., siblings in the tree structure) and the edge features between them. The updated feature vectors are then aggregated using a specified node aggregation function (e.g., max pooling, sum pooling, or average pooling) to obtain the parent node feature vector.\n",
        "\n",
        "The GNNChildEncoder class takes as input the child node features, a binary mask indicating which child nodes exist, the one-hot encoded edge type features, and the edge indices, and outputs the parent node feature vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG2iYCYHNkh5"
      },
      "outputs": [],
      "source": [
        "#  encode the child node features of a tree structure into a single parent node feature vector using a graph neural network (GNN) message-passing algorithm\n",
        "class GNNChildEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, node_feat_size, hidden_size, node_symmetric_type, \\\n",
        "            edge_symmetric_type, num_iterations, edge_type_num):\n",
        "        super(GNNChildEncoder, self).__init__()\n",
        "\n",
        "        self.node_symmetric_type = node_symmetric_type\n",
        "        self.edge_symmetric_type = edge_symmetric_type\n",
        "        self.num_iterations = num_iterations\n",
        "        self.edge_type_num = edge_type_num\n",
        "        print(\"Tree.num_sem in GNNChildEncoder:\", Tree.num_sem)\n",
        "        self.child_op = nn.Linear(node_feat_size + Tree.num_sem, hidden_size) #a linear layer that maps the concatenated child node feature vector and semantic label vector to a hidden feature space\n",
        "        self.node_edge_op = torch.nn.ModuleList()\n",
        "        for i in range(self.num_iterations):\n",
        "            self.node_edge_op.append(nn.Linear(hidden_size*2+edge_type_num, hidden_size))\n",
        "\n",
        "        self.parent_op = nn.Linear(hidden_size*(self.num_iterations+1), node_feat_size)\n",
        "\n",
        "    \"\"\"\n",
        "        Input Arguments:\n",
        "            child feats: b x max_childs x feat_dim\n",
        "            child exists: b x max_childs x 1\n",
        "            edge_type_onehot: b x num_edges x edge_type_num\n",
        "            edge_indices: b x num_edges x 2\n",
        "    \"\"\"\n",
        "    def forward(self, child_feats, child_exists, edge_type_onehot, edge_indices):\n",
        "        batch_size = child_feats.shape[0]\n",
        "        max_childs = child_feats.shape[1]\n",
        "        num_edges = edge_indices.shape[1]\n",
        "\n",
        "        if batch_size != 1:\n",
        "            raise ValueError('Currently only a single batch is supported.')\n",
        "\n",
        "        # perform MLP for child features\n",
        "        child_feats = torch.relu(self.child_op(child_feats))\n",
        "        hidden_size = child_feats.size(-1)\n",
        "\n",
        "        # zero out non-existent children\n",
        "        child_feats = child_feats * child_exists\n",
        "        child_feats = child_feats.view(1, max_childs, -1)\n",
        "\n",
        "        # combine node features before and after message-passing into one parent feature\n",
        "        iter_parent_feats = []\n",
        "        if self.node_symmetric_type == 'max':\n",
        "            iter_parent_feats.append(child_feats.max(dim=1)[0])\n",
        "        elif self.node_symmetric_type == 'sum':\n",
        "            iter_parent_feats.append(child_feats.sum(dim=1))\n",
        "        elif self.node_symmetric_type == 'avg':\n",
        "            iter_parent_feats.append(child_feats.sum(dim=1) / child_exists.sum(dim=1))\n",
        "        else:\n",
        "            raise ValueError(f'Unknown node symmetric type: {self.node_symmetric_type}')\n",
        "\n",
        "        if self.num_iterations > 0 and num_edges > 0:\n",
        "            edge_feats = edge_type_onehot\n",
        "\n",
        "        edge_indices_from = edge_indices[:, :, 0].view(-1, 1).expand(-1, hidden_size)\n",
        "\n",
        "        # perform Graph Neural Network for message-passing among sibling nodes\n",
        "        for i in range(self.num_iterations):\n",
        "            if num_edges > 0:\n",
        "                # MLP for edge features concatenated with adjacent node features\n",
        "                node_edge_feats = torch.cat([\n",
        "                    child_feats[0:1, edge_indices[0, :, 0], :], # start node features\n",
        "                    child_feats[0:1, edge_indices[0, :, 1], :], # end node features\n",
        "                    edge_feats], dim=2) # edge features\n",
        "\n",
        "                node_edge_feats = node_edge_feats.view(num_edges, -1)\n",
        "                node_edge_feats = torch.relu(self.node_edge_op[i](node_edge_feats))\n",
        "                node_edge_feats = node_edge_feats.view(num_edges, -1)\n",
        "\n",
        "                # aggregate information from neighboring nodes\n",
        "                new_child_feats = child_feats.new_zeros(max_childs, hidden_size)\n",
        "                if self.edge_symmetric_type == 'max':\n",
        "                    new_child_feats, _ = torch_scatter.scatter_max(node_edge_feats, edge_indices_from, dim=0, out=new_child_feats)\n",
        "                elif self.edge_symmetric_type == 'sum':\n",
        "                    new_child_feats = torch_scatter.scatter_add(node_edge_feats, edge_indices_from, dim=0, out=new_child_feats)\n",
        "                elif self.edge_symmetric_type == 'avg':\n",
        "                    new_child_feats = torch_scatter.scatter_mean(node_edge_feats, edge_indices_from, dim=0, out=new_child_feats)\n",
        "                else:\n",
        "                    raise ValueError(f'Unknown edge symmetric type: {self.edge_symmetric_type}')\n",
        "\n",
        "                child_feats = new_child_feats.view(1, max_childs, hidden_size)\n",
        "\n",
        "            # combine node features before and after message-passing into one parent feature\n",
        "            if self.node_symmetric_type == 'max':\n",
        "                iter_parent_feats.append(child_feats.max(dim=1)[0])\n",
        "            elif self.node_symmetric_type == 'sum':\n",
        "                iter_parent_feats.append(child_feats.sum(dim=1))\n",
        "            elif self.node_symmetric_type == 'avg':\n",
        "                iter_parent_feats.append(child_feats.sum(dim=1) / child_exists.sum(dim=1))\n",
        "            else:\n",
        "                raise ValueError(f'Unknown node symmetric type: {self.node_symmetric_type}')\n",
        "\n",
        "        # concatenation of the parent features from all iterations (as in GIN, like skip connections)\n",
        "        parent_feat = torch.cat(iter_parent_feats, dim=1)\n",
        "\n",
        "        # back to standard feature space size\n",
        "        parent_feat = torch.relu(self.parent_op(parent_feat))\n",
        "\n",
        "        return parent_feat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1s_j5hnkVta"
      },
      "source": [
        "The RecursiveEncoder is used to encode the structure of a 3D object as a latent feature vector using a recursive neural network.\n",
        "\n",
        "The encode_structure method takes as input a 3D object obj and returns its encoded latent feature vector. The encoding process is performed recursively, starting at the root node of the object's hierarchical tree structure and traversing down the tree to its leaf nodes. At each node, the child node features are concatenated with their semantic labels and passed through the child_encoder module, which applies a graph neural network (GNN) message-passing algorithm to aggregate information from the child nodes and generate a hidden feature vector for the parent node.\n",
        "\n",
        "The encoded feature vectors are then used to reconstruct the original object, or for other downstream tasks such as object classification or shape retrieval.\n",
        "\n",
        "If the variational flag is set to True, the output feature vector is passed through a Sampler module that generates a latent code that is normally distributed. This can be used for variational autoencoder training, where the goal is to learn a generative model that can generate new objects similar to those in the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaFaigdgngvg"
      },
      "source": [
        "Let's say we have a tree structure that represents a 3D scene with two child nodes. One child node represents a chair and the other child node represents a table. The chair node has an encoded feature vector of length 64, and the table node has an encoded feature vector of length 64 as well. We also have a dictionary of semantic labels that associates the label \"chair\" with a one-hot vector of length 8, and the label \"table\" with a one-hot vector of length 8.\n",
        "\n",
        "To incorporate the semantic labels into the encoding process, we concatenate the one-hot semantic vectors with their corresponding child node feature vectors. So the final feature vector for the chair node would be a vector of length 72, where the first 64 elements correspond to the encoded feature vector for the chair, and the last 8 elements correspond to the semantic label one-hot vector for \"chair\". Similarly, the final feature vector for the table node would be a vector of length 72, where the first 64 elements correspond to the encoded feature vector for the table, and the last 8 elements correspond to the semantic label one-hot vector for \"table\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK16eDLCiJ7Q"
      },
      "outputs": [],
      "source": [
        "class RecursiveEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, config, variational=False, probabilistic=True):\n",
        "        super(RecursiveEncoder, self).__init__()\n",
        "        self.conf = config\n",
        "\n",
        "        self.box_encoder = BoxEncoder(feature_size=config.feature_size)\n",
        "\n",
        "        self.child_encoder = GNNChildEncoder(\n",
        "            node_feat_size=config.feature_size,\n",
        "            hidden_size=config.hidden_size,\n",
        "            node_symmetric_type=config.node_symmetric_type,\n",
        "            edge_symmetric_type=config.edge_symmetric_type,\n",
        "            num_iterations=config.num_gnn_iterations,\n",
        "            edge_type_num=len(config.edge_types))\n",
        "\n",
        "        if variational:\n",
        "            self.sample_encoder = Sampler(feature_size=config.feature_size, \\\n",
        "                    hidden_size=config.hidden_size, probabilistic=probabilistic)\n",
        "\n",
        "    def encode_node(self, node):\n",
        "        if node.is_leaf:\n",
        "            return self.box_encoder(node.get_box_quat().view(1, -1))\n",
        "        else:\n",
        "            # get features of all children\n",
        "            child_feats = []\n",
        "            for child in node.children:\n",
        "              # To incorporate the semantic information into the encoding process,\n",
        "              # the child node features are concatenated with their\n",
        "              # corresponding semantic labels. This results in a\n",
        "              # new feature vector that combines both geometric/appearance\n",
        "              # information and semantic information\n",
        "                cur_child_feat = torch.cat([self.encode_node(child), child.get_semantic_one_hot()], dim=1)\n",
        "                child_feats.append(cur_child_feat.unsqueeze(dim=1))\n",
        "            child_feats = torch.cat(child_feats, dim=1)\n",
        "\n",
        "            if child_feats.shape[1] > self.conf.max_child_num:\n",
        "                raise ValueError('Node has too many children.')\n",
        "\n",
        "            # pad with zeros\n",
        "            if child_feats.shape[1] < self.conf.max_child_num:\n",
        "                padding = child_feats.new_zeros(child_feats.shape[0], \\\n",
        "                        self.conf.max_child_num-child_feats.shape[1], child_feats.shape[2])\n",
        "                child_feats = torch.cat([child_feats, padding], dim=1)\n",
        "\n",
        "            # 1 if the child exists, 0 if it is padded\n",
        "            child_exists = child_feats.new_zeros(child_feats.shape[0], self.conf.max_child_num, 1)\n",
        "            child_exists[:, :len(node.children), :] = 1\n",
        "\n",
        "            # get feature of current node (parent of the children)\n",
        "            edge_type_onehot, edge_indices = node.edge_tensors(\n",
        "                edge_types=self.conf.edge_types, device=child_feats.device, type_onehot=True)\n",
        "\n",
        "            return self.child_encoder(child_feats, child_exists, edge_type_onehot, edge_indices)\n",
        "\n",
        "    def encode_structure(self, obj): # obj is an instance of a 'Tree' class representing the 3D object\n",
        "        root_latent = self.encode_node(obj.root)\n",
        "        return self.sample_encoder(root_latent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcYTc4wAodEA"
      },
      "source": [
        "The LeafClassifier module can be trained using a binary cross-entropy loss function to predict the class label of a leaf node in a tree. It can be used as a component of a larger tree-structured neural network that performs some task on the input tree structure. For example, it can be used as a component in a tree-structured object detection or segmentation network to classify the type of object represented by a leaf node in the tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TvLFPzlnkqY"
      },
      "outputs": [],
      "source": [
        "# LeafClassifier takes as input a feature vector of a leaf node in a tree and\n",
        "#  outputs a binary classification label (i.e. either 0 or 1).\n",
        "class LeafClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, feature_size, hidden_size):\n",
        "        super(LeafClassifier, self).__init__()\n",
        "        self.mlp1 = nn.Linear(feature_size, hidden_size)\n",
        "        self.mlp2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, input_feature):\n",
        "        output = torch.relu(self.mlp1(input_feature))\n",
        "        output = self.mlp2(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IImSYJx0o6xf"
      },
      "source": [
        "\n",
        "The SampleDecoder module is a PyTorch neural network that takes as input a feature vector sampled from a latent space and outputs a reconstructed feature vector in the original feature space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKoKGEqRofDI"
      },
      "outputs": [],
      "source": [
        "class SampleDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, feature_size, hidden_size):\n",
        "        super(SampleDecoder, self).__init__()\n",
        "        self.mlp1 = nn.Linear(feature_size, hidden_size)\n",
        "        self.mlp2 = nn.Linear(hidden_size, feature_size)\n",
        "\n",
        "    def forward(self, input_feature):\n",
        "        output = torch.relu(self.mlp1(input_feature))\n",
        "        output = torch.relu(self.mlp2(output))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izBrvdiZp9lz"
      },
      "source": [
        "\n",
        "The BoxDecoder is a PyTorch neural network module that takes a parent feature vector as input and outputs a bounding box representation in 3D space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFa1Sridp9_g"
      },
      "outputs": [],
      "source": [
        "class BoxDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, feature_size, hidden_size):\n",
        "        super(BoxDecoder, self).__init__()\n",
        "        self.mlp = nn.Linear(feature_size, hidden_size)\n",
        "        self.center = nn.Linear(hidden_size, 3)\n",
        "        self.size = nn.Linear(hidden_size, 3)\n",
        "        self.quat = nn.Linear(hidden_size, 4) #  4D quaternion representation of the orientation of the box.\n",
        "\n",
        "    def forward(self, parent_feature):\n",
        "        feat = torch.relu(self.mlp(parent_feature))\n",
        "        center = torch.tanh(self.center(feat))\n",
        "        size = torch.sigmoid(self.size(feat)) * 2\n",
        "        quat_bias = feat.new_tensor([[1.0, 0.0, 0.0, 0.0]]) #to ensure that the quaternion has a non-zero norm and can be normalized correctly\n",
        "        quat = self.quat(feat).add(quat_bias)\n",
        "        quat = quat / (1e-12 + quat.pow(2).sum(dim=1).unsqueeze(dim=1).sqrt()) # normalized\n",
        "        vector = torch.cat([center, size, quat], dim=1)\n",
        "        return vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8CW7YnZr6e-"
      },
      "source": [
        "This is a class for decoding the sampled latent variables into tree structures. It takes as input the parent feature, which is the sampled latent variable of the root node, and it outputs the features, semantics, and existence probabilities of all the child nodes, as well as the existence probabilities of all the edges in the tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8niocorkl05v"
      },
      "source": [
        "\n",
        "In the GNNChildDecoder, the iterative message passing is used to update the latent features of child nodes based on the features of their neighbors and the edges connecting them. This is done by concatenating the features of the start node, the end node, and the edge features, passing them through a linear layer, and then aggregating the information from the neighboring nodes using a specific symmetric function (max, sum, or average).\n",
        "\n",
        "After each iteration, a new set of latent features is generated for each child node. By concatenating the results of all iterations for each child node, we can capture a more comprehensive representation of the child node, including its local and global information. This is similar to the idea of skip connections in residual networks.\n",
        "\n",
        "The concatenated features are then passed through another linear layer to transform the concatenated feature space back to the original size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClCdI3Tjry-I"
      },
      "outputs": [],
      "source": [
        "class GNNChildDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, node_feat_size, hidden_size, max_child_num, \\\n",
        "            edge_symmetric_type, num_iterations, edge_type_num):\n",
        "        super(GNNChildDecoder, self).__init__()\n",
        "\n",
        "        self.max_child_num = max_child_num\n",
        "        self.hidden_size = hidden_size\n",
        "        self.edge_symmetric_type = edge_symmetric_type\n",
        "        self.num_iterations = num_iterations\n",
        "        self.edge_type_num = edge_type_num\n",
        "        # MLPs to map parent features to child features\n",
        "        self.mlp_parent = nn.Linear(node_feat_size, hidden_size*max_child_num) # each child has its own representation\n",
        "        self.mlp_exists = nn.Linear(hidden_size, 1)\n",
        "        self.mlp_sem = nn.Linear(hidden_size, Tree.num_sem)\n",
        "        self.mlp_child = nn.Linear(hidden_size, node_feat_size) # final representation of each child node\n",
        "        # MLPs for edge existence prediction\n",
        "        self.mlp_edge_latent = nn.Linear(hidden_size*2, hidden_size) #takes the concatenation of two child node feature vectors\n",
        "        self.mlp_edge_exists = nn.ModuleList()\n",
        "        for i in range(edge_type_num):\n",
        "            self.mlp_edge_exists.append(nn.Linear(hidden_size, 1))\n",
        "        # Node-edge operations for message passing\n",
        "        self.node_edge_op = torch.nn.ModuleList()\n",
        "        for i in range(self.num_iterations):\n",
        "            self.node_edge_op.append(nn.Linear(hidden_size*3+edge_type_num, hidden_size))\n",
        "        # Final MLPs for child feature and semantic prediction\n",
        "        self.mlp_child = nn.Linear(hidden_size*(self.num_iterations+1), hidden_size) #maps the concatenated child features from all iterations to generate the final child features\n",
        "        self.mlp_sem = nn.Linear(hidden_size, Tree.num_sem)\n",
        "        self.mlp_child2 = nn.Linear(hidden_size, node_feat_size) # take the output of mlp_child\n",
        "\n",
        "    def forward(self, parent_feature):\n",
        "        batch_size = parent_feature.shape[0]\n",
        "        feat_size = parent_feature.shape[1]\n",
        "\n",
        "        if batch_size != 1: # each time deals only one tree ( nodes may differ from different trees)\n",
        "            raise ValueError('Only batch size 1 supported for now.')\n",
        "\n",
        "        parent_feature = torch.relu(self.mlp_parent(parent_feature))\n",
        "        child_feats = parent_feature.view(batch_size, self.max_child_num, self.hidden_size)\n",
        "\n",
        "        # node existence\n",
        "        child_exists_logits = self.mlp_exists(child_feats.view(batch_size*self.max_child_num, self.hidden_size))\n",
        "        child_exists_logits = child_exists_logits.view(batch_size, self.max_child_num, 1)\n",
        "\n",
        "        # edge features\n",
        "        edge_latents = torch.cat([\n",
        "            child_feats.view(batch_size, self.max_child_num, 1, feat_size).expand(-1, -1, self.max_child_num, -1),\n",
        "            child_feats.view(batch_size, 1, self.max_child_num, feat_size).expand(-1, self.max_child_num, -1, -1)\n",
        "            ], dim=3)\n",
        "        edge_latents = torch.relu(self.mlp_edge_latent(edge_latents))\n",
        "\n",
        "        # edge existence prediction\n",
        "        edge_exists_logits_per_type = []\n",
        "        for i in range(self.edge_type_num):\n",
        "            edge_exists_logits_cur_type = self.mlp_edge_exists[i](edge_latents).view(\\\n",
        "                    batch_size, self.max_child_num, self.max_child_num, 1)\n",
        "            edge_exists_logits_per_type.append(edge_exists_logits_cur_type)\n",
        "        edge_exists_logits = torch.cat(edge_exists_logits_per_type, dim=3)\n",
        "\n",
        "        \"\"\"\n",
        "            decoding stage message passing\n",
        "            there are several possible versions, this is a simple one:\n",
        "            use a fixed set of edges, consisting of existing edges connecting existing nodes\n",
        "            this set of edges does not change during iterations\n",
        "            iteratively update the child latent features\n",
        "            then use these child latent features to compute child features and semantics\n",
        "        \"\"\"\n",
        "        # get edges that exist between nodes that exist\n",
        "        edge_indices = torch.nonzero(edge_exists_logits > 0)\n",
        "        edge_types = edge_indices[:, 3]\n",
        "        edge_indices = edge_indices[:, 1:3]\n",
        "        nodes_exist_mask = (child_exists_logits[0, edge_indices[:, 0], 0] > 0) \\\n",
        "                & (child_exists_logits[0, edge_indices[:, 1], 0] > 0)\n",
        "        edge_indices = edge_indices[nodes_exist_mask, :]\n",
        "        edge_types = edge_types[nodes_exist_mask]\n",
        "\n",
        "        # get latent features for the edges\n",
        "        edge_feats_mp = edge_latents[0:1, edge_indices[:, 0], edge_indices[:, 1], :]\n",
        "\n",
        "        # append edge type to edge features, so the network has information which\n",
        "        # of the possibly multiple edges between two nodes it is working with\n",
        "        edge_type_logit = edge_exists_logits[0:1, edge_indices[:, 0], edge_indices[:, 1], :]\n",
        "        edge_type_logit = edge_feats_mp.new_zeros(edge_feats_mp.shape[:2]+(self.edge_type_num,))\n",
        "        edge_type_logit[0:1, range(edge_type_logit.shape[1]), edge_types] = \\\n",
        "                edge_exists_logits[0:1, edge_indices[:, 0], edge_indices[:, 1], edge_types]\n",
        "        edge_feats_mp = torch.cat([edge_feats_mp, edge_type_logit], dim=2)\n",
        "\n",
        "        num_edges = edge_indices.shape[0]\n",
        "        max_childs = child_feats.shape[1]\n",
        "\n",
        "        iter_child_feats = [child_feats] # zeroth iteration\n",
        "\n",
        "        if self.num_iterations > 0 and num_edges > 0:\n",
        "            edge_indices_from = edge_indices[:, 0].view(-1, 1).expand(-1, self.hidden_size)\n",
        "\n",
        "        for i in range(self.num_iterations):\n",
        "            if num_edges > 0:\n",
        "                node_edge_feats = torch.cat([\n",
        "                    child_feats[0:1, edge_indices[:, 0], :], # start node features\n",
        "                    child_feats[0:1, edge_indices[:, 1], :], # end node features\n",
        "                    edge_feats_mp], dim=2) # edge features\n",
        "\n",
        "                node_edge_feats = node_edge_feats.view(num_edges, -1)\n",
        "                node_edge_feats = torch.relu(self.node_edge_op[i](node_edge_feats))\n",
        "\n",
        "                # aggregate information from neighboring nodes\n",
        "                new_child_feats = child_feats.new_zeros(max_childs, self.hidden_size)\n",
        "                if self.edge_symmetric_type == 'max':\n",
        "                    new_child_feats, _ = torch_scatter.scatter_max(node_edge_feats, edge_indices_from, dim=0, out=new_child_feats)\n",
        "                elif self.edge_symmetric_type == 'sum':\n",
        "                    new_child_feats = torch_scatter.scatter_add(node_edge_feats, edge_indices_from, dim=0, out=new_child_feats)\n",
        "                elif self.edge_symmetric_type == 'avg':\n",
        "                    new_child_feats = torch_scatter.scatter_mean(node_edge_feats, edge_indices_from, dim=0, out=new_child_feats)\n",
        "                else:\n",
        "                    raise ValueError(f'Unknown edge symmetric type: {self.edge_symmetric_type}')\n",
        "\n",
        "                child_feats = new_child_feats.view(1, max_childs, self.hidden_size)\n",
        "\n",
        "            # save child features of this iteration\n",
        "            iter_child_feats.append(child_feats)\n",
        "\n",
        "        # concatenation of the child features from all iterations (as in GIN, like skip connections)\n",
        "        child_feats = torch.cat(iter_child_feats, dim=2)\n",
        "\n",
        "        # transform concatenation back to original feature space size\n",
        "        child_feats = child_feats.view(-1, self.hidden_size*(self.num_iterations+1))\n",
        "        child_feats = torch.relu(self.mlp_child(child_feats))\n",
        "        child_feats = child_feats.view(batch_size, self.max_child_num, self.hidden_size)\n",
        "\n",
        "        # node semantics\n",
        "        child_sem_logits = self.mlp_sem(child_feats.view(-1, self.hidden_size))\n",
        "        child_sem_logits = child_sem_logits.view(batch_size, self.max_child_num, Tree.num_sem)\n",
        "\n",
        "        # node features\n",
        "        child_feats = self.mlp_child2(child_feats.view(-1, self.hidden_size))\n",
        "        child_feats = child_feats.view(batch_size, self.max_child_num, feat_size)\n",
        "        child_feats = torch.relu(child_feats)\n",
        "\n",
        "        return child_feats, child_sem_logits, child_exists_logits, edge_exists_logits\n",
        "        '''\n",
        "        child_feats: The tensor of child features, where each row corresponds to a child node and each column corresponds to a feature dimension.\n",
        "\n",
        "        child_sem_logits: The tensor of child node semantic label logits, where each row corresponds to a child node and each column corresponds\n",
        "        to a semantic label. These logits are later used to predict the final semantic labels for the child nodes.\n",
        "\n",
        "        child_exists_logits: The tensor of child node existence logits, where each row corresponds to a child node and the single column corresponds\n",
        "        to the probability of the child node existing. These logits are used to predict whether a child node exists or not.\n",
        "\n",
        "        edge_exists_logits: The tensor of edge existence logits, where each row corresponds to an edge and each column corresponds to the probability\n",
        "        of the edge existing. These logits are used to predict whether an edge exists or not.\n",
        "        '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQhtr4jeybEj"
      },
      "source": [
        "The RecursiveDecoder is a PyTorch neural network module that takes as input a latent vector z and generates a tree structure with boxes at the leaf nodes. The module is composed of two parts: a sample_decoder and a child_decoder. The sample_decoder takes as input the latent vector z and outputs the root node of the tree. The child_decoder takes as input the node features and outputs the features for its children.\n",
        "\n",
        "The node_recon_loss method is responsible for computing the reconstruction loss for each node in the generated tree, as well as the loss for the relationship between its children. It does this recursively by calling itself on the children of each node until it reaches the leaf nodes.\n",
        "\n",
        "The module uses several loss functions, including binary cross-entropy loss, mean squared error loss, and Chamfer distance loss, to train the network to generate 3D shapes that resemble the ground truth shapes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwAzM2b0vMLh"
      },
      "source": [
        "The boxLossEstimator method calculates the box loss between the predicted bounding box and the ground truth bounding box. It takes as input the predicted box feature and the ground truth box feature. The box feature contains 6 values: center x, y, z coordinates, length, width, and height. The method first transforms the unit cube to the predicted box's coordinate system and then calculates the surface reweighting using the predicted box's width, length, and height values. It does the same for the ground truth box. Then, it calculates the chamfer distance between the transformed predicted box point cloud and the transformed ground truth box point cloud. Finally, it computes the weighted sum of the chamfer distance and returns it as the box loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqb2HhHUvWth"
      },
      "source": [
        "The anchorLossEstimator method calculates the anchor loss between the predicted bounding box and the ground truth bounding box. It takes as input the predicted box feature and the ground truth box feature. The method first transforms the anchor point cloud to the predicted box's coordinate system and does the same for the ground truth box. Then, it calculates the chamfer distance between the transformed predicted anchor point cloud and the transformed ground truth anchor point cloud. Finally, it computes the mean of the two chamfer distances and returns it as the anchor loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVSs-tr9IqcR"
      },
      "outputs": [],
      "source": [
        "\n",
        "class RecursiveDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(RecursiveDecoder, self).__init__()\n",
        "\n",
        "        self.conf = config\n",
        "\n",
        "        #decode the latent feature vector of a node into a set of 3D box parameters (center, size, and orientation).\n",
        "        self.box_decoder = BoxDecoder(config.feature_size, config.hidden_size)\n",
        "\n",
        "        self.child_decoder = GNNChildDecoder(\n",
        "            node_feat_size=config.feature_size,\n",
        "            hidden_size=config.hidden_size,\n",
        "            max_child_num=config.max_child_num,\n",
        "            edge_symmetric_type=config.edge_symmetric_type,\n",
        "            num_iterations=config.num_dec_gnn_iterations,\n",
        "            edge_type_num=len(config.edge_types))\n",
        "\n",
        "        self.sample_decoder = SampleDecoder(config.feature_size, config.hidden_size)\n",
        "\n",
        "        self.leaf_classifier = LeafClassifier(config.feature_size, config.hidden_size)\n",
        "\n",
        "        self.bceLoss = nn.BCEWithLogitsLoss(reduction='none')\n",
        "        self.chamferLoss = ChamferDistance()\n",
        "        self.semCELoss = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "        self.register_buffer('unit_cube', torch.from_numpy(load_pts('./code/cube.pts')))\n",
        "        self.register_buffer('anchor', torch.from_numpy(load_pts('./code/anchor.pts')))\n",
        "\n",
        "    def boxLossEstimator(self, box_feature, gt_box_feature):\n",
        "        pred_box_pc = transform_pc_batch(self.unit_cube, box_feature)\n",
        "        with torch.no_grad():\n",
        "            pred_reweight = get_surface_reweighting_batch(box_feature[:, 3:6], self.unit_cube.size(0))\n",
        "        gt_box_pc = transform_pc_batch(self.unit_cube, gt_box_feature)\n",
        "        with torch.no_grad():\n",
        "            gt_reweight = get_surface_reweighting_batch(gt_box_feature[:, 3:6], self.unit_cube.size(0))\n",
        "        dist1, dist2 = self.chamferLoss(gt_box_pc, pred_box_pc)\n",
        "        loss1 = (dist1 * gt_reweight).sum(dim=1) / (gt_reweight.sum(dim=1) + 1e-12)\n",
        "        loss2 = (dist2 * pred_reweight).sum(dim=1) / (pred_reweight.sum(dim=1) + 1e-12)\n",
        "        loss = (loss1 + loss2) / 2\n",
        "        return loss\n",
        "\n",
        "    def anchorLossEstimator(self, box_feature, gt_box_feature):\n",
        "        pred_anchor_pc = transform_pc_batch(self.anchor, box_feature, anchor=True)\n",
        "        gt_anchor_pc = transform_pc_batch(self.anchor, gt_box_feature, anchor=True)\n",
        "        dist1, dist2 = self.chamferLoss(gt_anchor_pc, pred_anchor_pc)\n",
        "        loss = (dist1.mean(dim=1) + dist2.mean(dim=1)) / 2\n",
        "        return loss\n",
        "\n",
        "    def isLeafLossEstimator(self, is_leaf_logit, gt_is_leaf):\n",
        "        return self.bceLoss(is_leaf_logit, gt_is_leaf).view(-1)\n",
        "\n",
        "    # decode a root code into a tree structure\n",
        "    def decode_structure(self, z, max_depth):\n",
        "        root_latent = self.sample_decoder(z)\n",
        "        root = self.decode_node(root_latent, max_depth, Tree.root_sem)\n",
        "        obj = Tree(root=root)\n",
        "        return obj\n",
        "\n",
        "    # decode a part node\n",
        "    def decode_node(self, node_latent, max_depth, full_label, is_leaf=False):\n",
        "        if node_latent.shape[0] != 1:\n",
        "            raise ValueError('Node decoding does not support batch_size > 1.')\n",
        "\n",
        "        is_leaf_logit = self.leaf_classifier(node_latent)\n",
        "        node_is_leaf = is_leaf_logit.item() > 0\n",
        "\n",
        "        # use maximum depth to avoid potential infinite recursion\n",
        "        if max_depth < 1:\n",
        "            is_leaf = True\n",
        "\n",
        "        # decode the current part box\n",
        "        box = self.box_decoder(node_latent)\n",
        "\n",
        "        if node_is_leaf or is_leaf:\n",
        "            ret = Tree.Node(is_leaf=True, full_label=full_label, label=full_label.split('/')[-1])\n",
        "            ret.set_from_box_quat(box.view(-1))\n",
        "            return ret\n",
        "        else:\n",
        "            child_feats, child_sem_logits, child_exists_logit, edge_exists_logits = \\\n",
        "                    self.child_decoder(node_latent)\n",
        "\n",
        "            child_sem_logits = child_sem_logits.cpu().numpy().squeeze()\n",
        "\n",
        "            # children\n",
        "            child_nodes = []\n",
        "            child_idx = {}\n",
        "            for ci in range(child_feats.shape[1]):\n",
        "                if torch.sigmoid(child_exists_logit[:, ci, :]).item() > 0.5:\n",
        "                    idx = np.argmax(child_sem_logits[ci, Tree.part_name2cids[full_label]])\n",
        "                    idx = Tree.part_name2cids[full_label][idx]\n",
        "                    child_full_label = Tree.part_id2name[idx]\n",
        "                    child_nodes.append(self.decode_node(\\\n",
        "                            child_feats[:, ci, :], max_depth-1, child_full_label, \\\n",
        "                            is_leaf=(child_full_label not in Tree.part_non_leaf_sem_names)))\n",
        "                    child_idx[ci] = len(child_nodes) - 1\n",
        "\n",
        "            # edges\n",
        "            child_edges = []\n",
        "            nz_inds = torch.nonzero(torch.sigmoid(edge_exists_logits) > 0.5)\n",
        "            edge_from = nz_inds[:, 1]\n",
        "            edge_to = nz_inds[:, 2]\n",
        "            edge_type = nz_inds[:, 3]\n",
        "\n",
        "            for i in range(edge_from.numel()):\n",
        "                cur_edge_from = edge_from[i].item()\n",
        "                cur_edge_to = edge_to[i].item()\n",
        "                cur_edge_type = edge_type[i].item()\n",
        "\n",
        "                if cur_edge_from in child_idx and cur_edge_to in child_idx:\n",
        "                    child_edges.append({\n",
        "                        'part_a': child_idx[cur_edge_from],\n",
        "                        'part_b': child_idx[cur_edge_to],\n",
        "                        'type': self.conf.edge_types[cur_edge_type]})\n",
        "\n",
        "            node = Tree.Node(is_leaf=False, children=child_nodes, edges=child_edges, \\\n",
        "                    full_label=full_label, label=full_label.split('/')[-1])\n",
        "            node.set_from_box_quat(box.view(-1))\n",
        "            return node\n",
        "\n",
        "    # use gt structure, compute the reconstruction losses\n",
        "    def structure_recon_loss(self, z, gt_tree):\n",
        "        root_latent = self.sample_decoder(z)\n",
        "        losses, _, _ = self.node_recon_loss(root_latent, gt_tree.root)\n",
        "        return losses\n",
        "\n",
        "    # compute per-node loss + children relationship loss\n",
        "    def node_recon_loss(self, node_latent, gt_node):\n",
        "        if gt_node.is_leaf:\n",
        "            box = self.box_decoder(node_latent)\n",
        "            box_loss = self.boxLossEstimator(box, gt_node.get_box_quat().view(1, -1))\n",
        "            anchor_loss = self.anchorLossEstimator(box, gt_node.get_box_quat().view(1, -1))\n",
        "            is_leaf_logit = self.leaf_classifier(node_latent)\n",
        "            is_leaf_loss = self.isLeafLossEstimator(is_leaf_logit, is_leaf_logit.new_tensor(gt_node.is_leaf).view(1, -1))\n",
        "            return {'box': box_loss, 'leaf': is_leaf_loss, 'anchor': anchor_loss,\n",
        "                    'exists': torch.zeros_like(box_loss), 'semantic': torch.zeros_like(box_loss),\n",
        "                    'edge_exists': torch.zeros_like(box_loss),\n",
        "                    'sym': torch.zeros_like(box_loss), 'adj': torch.zeros_like(box_loss)}, box, box\n",
        "        else:\n",
        "            child_feats, child_sem_logits, child_exists_logits, edge_exists_logits = \\\n",
        "                    self.child_decoder(node_latent)\n",
        "\n",
        "            # generate box prediction for each child\n",
        "            feature_len = node_latent.size(1)\n",
        "            child_pred_boxes = self.box_decoder(child_feats.view(-1, feature_len))\n",
        "            num_child_parts = child_pred_boxes.size(0)\n",
        "\n",
        "            # perform hungarian matching between pred boxes and gt boxes\n",
        "            with torch.no_grad():\n",
        "                child_gt_boxes = torch.cat([child_node.get_box_quat().view(1, -1) for child_node in gt_node.children], dim=0)\n",
        "                num_gt = child_gt_boxes.size(0)\n",
        "\n",
        "                child_pred_boxes_tiled = child_pred_boxes.unsqueeze(dim=0).repeat(num_gt, 1, 1)\n",
        "                child_gt_boxes_tiled = child_gt_boxes.unsqueeze(dim=1).repeat(1, num_child_parts, 1)\n",
        "\n",
        "                dist_mat = self.boxLossEstimator(child_gt_boxes_tiled.view(-1, 10), child_pred_boxes_tiled.view(-1, 10)).view(-1, num_gt, num_child_parts)\n",
        "\n",
        "                _, matched_gt_idx, matched_pred_idx = linear_assignment(dist_mat)\n",
        "\n",
        "                # get edge ground truth\n",
        "                edge_type_list_gt, edge_indices_gt = gt_node.edge_tensors(\n",
        "                    edge_types=self.conf.edge_types, device=child_feats.device, type_onehot=False)\n",
        "\n",
        "                gt2pred = {gt_idx: pred_idx for gt_idx, pred_idx in zip(matched_gt_idx, matched_pred_idx)}\n",
        "                edge_exists_gt = torch.zeros_like(edge_exists_logits)\n",
        "\n",
        "                sym_from = []; sym_to = []; sym_mat = []; sym_type = []; adj_from = []; adj_to = [];\n",
        "                for i in range(edge_indices_gt.shape[1]//2):\n",
        "                    if edge_indices_gt[0, i, 0].item() not in gt2pred or edge_indices_gt[0, i, 1].item() not in gt2pred:\n",
        "                        \"\"\"\n",
        "                            one of the adjacent nodes of the current gt edge was not matched\n",
        "                            to any node in the prediction, ignore this edge\n",
        "                        \"\"\"\n",
        "                        continue\n",
        "\n",
        "                    # correlate gt edges to pred edges\n",
        "                    edge_from_idx = gt2pred[edge_indices_gt[0, i, 0].item()]\n",
        "                    edge_to_idx = gt2pred[edge_indices_gt[0, i, 1].item()]\n",
        "                    edge_exists_gt[:, edge_from_idx, edge_to_idx, edge_type_list_gt[0:1, i]] = 1\n",
        "                    edge_exists_gt[:, edge_to_idx, edge_from_idx, edge_type_list_gt[0:1, i]] = 1\n",
        "\n",
        "                    # compute binary edge parameters for each matched pred edge\n",
        "                    if edge_type_list_gt[0, i].item() == 0: # ADJ\n",
        "                        adj_from.append(edge_from_idx)\n",
        "                        adj_to.append(edge_to_idx)\n",
        "                    else:   # SYM\n",
        "                        if edge_type_list_gt[0, i].item() == 1: # ROT_SYM\n",
        "                            mat1to2, mat2to1 = compute_sym.compute_rot_sym(child_pred_boxes[edge_from_idx].cpu().detach().numpy(), child_pred_boxes[edge_to_idx].cpu().detach().numpy())\n",
        "                        elif edge_type_list_gt[0, i].item() == 2: # TRANS_SYM\n",
        "                            mat1to2, mat2to1 = compute_sym.compute_trans_sym(child_pred_boxes[edge_from_idx].cpu().detach().numpy(), child_pred_boxes[edge_to_idx].cpu().detach().numpy())\n",
        "                        else:   # REF_SYM\n",
        "                            mat1to2, mat2to1 = compute_sym.compute_ref_sym(child_pred_boxes[edge_from_idx].cpu().detach().numpy(), child_pred_boxes[edge_to_idx].cpu().detach().numpy())\n",
        "                        sym_from.append(edge_from_idx)\n",
        "                        sym_to.append(edge_to_idx)\n",
        "                        sym_mat.append(torch.tensor(mat1to2, dtype=torch.float32, device=self.conf.device).view(1, 3, 4))\n",
        "                        sym_type.append(edge_type_list_gt[0, i].item())\n",
        "\n",
        "            # train the current node to be non-leaf\n",
        "            is_leaf_logit = self.leaf_classifier(node_latent)\n",
        "            is_leaf_loss = self.isLeafLossEstimator(is_leaf_logit, is_leaf_logit.new_tensor(gt_node.is_leaf).view(1, -1))\n",
        "\n",
        "            # train the current node box to gt\n",
        "            all_boxes = []; all_leaf_boxes = [];\n",
        "            box = self.box_decoder(node_latent)\n",
        "            all_boxes.append(box)\n",
        "            box_loss = self.boxLossEstimator(box, gt_node.get_box_quat().view(1, -1))\n",
        "            anchor_loss = self.anchorLossEstimator(box, gt_node.get_box_quat().view(1, -1))\n",
        "\n",
        "            # gather information\n",
        "            child_sem_gt_labels = []\n",
        "            child_sem_pred_logits = []\n",
        "            child_box_gt = []\n",
        "            child_box_pred = []\n",
        "            child_exists_gt = torch.zeros_like(child_exists_logits)\n",
        "            for i in range(len(matched_gt_idx)):\n",
        "                child_sem_gt_labels.append(gt_node.children[matched_gt_idx[i]].get_semantic_id())\n",
        "                child_sem_pred_logits.append(child_sem_logits[0, matched_pred_idx[i], :].view(1, -1))\n",
        "                child_box_gt.append(gt_node.children[matched_gt_idx[i]].get_box_quat().view(1, -1))\n",
        "                child_box_pred.append(child_pred_boxes[matched_pred_idx[i], :].view(1, -1))\n",
        "                child_exists_gt[:, matched_pred_idx[i], :] = 1\n",
        "\n",
        "            # train semantic labels\n",
        "            child_sem_pred_logits = torch.cat(child_sem_pred_logits, dim=0)\n",
        "            child_sem_gt_labels = torch.tensor(child_sem_gt_labels, dtype=torch.int64, \\\n",
        "                    device=child_sem_pred_logits.device)\n",
        "            semantic_loss = self.semCELoss(child_sem_pred_logits, child_sem_gt_labels)\n",
        "            semantic_loss = semantic_loss.sum()\n",
        "\n",
        "            # train unused boxes to zeros\n",
        "            unmatched_boxes = []\n",
        "            for i in range(num_child_parts):\n",
        "                if i not in matched_pred_idx:\n",
        "                    unmatched_boxes.append(child_pred_boxes[i, 3:6].view(1, -1))\n",
        "            if len(unmatched_boxes) > 0:\n",
        "                unmatched_boxes = torch.cat(unmatched_boxes, dim=0)\n",
        "                unused_box_loss = unmatched_boxes.pow(2).sum() * 0.01\n",
        "            else:\n",
        "                unused_box_loss = 0.0\n",
        "\n",
        "            # train exist scores\n",
        "            child_exists_loss = F.binary_cross_entropy_with_logits(\\\n",
        "                input=child_exists_logits, target=child_exists_gt, reduction='none')\n",
        "            child_exists_loss = child_exists_loss.sum()\n",
        "\n",
        "            # train edge exists scores\n",
        "            edge_exists_loss = F.binary_cross_entropy_with_logits(\\\n",
        "                    input=edge_exists_logits, target=edge_exists_gt, reduction='none')\n",
        "            edge_exists_loss = edge_exists_loss.sum()\n",
        "            # rescale to make it comparable to other losses,\n",
        "            # which are in the order of the number of child nodes\n",
        "            edge_exists_loss = edge_exists_loss / (edge_exists_gt.shape[2]*edge_exists_gt.shape[3])\n",
        "\n",
        "            # compute and train binary losses\n",
        "            sym_loss = 0\n",
        "            if len(sym_from) > 0:\n",
        "                sym_from_th = torch.tensor(sym_from, dtype=torch.long, device=self.conf.device)\n",
        "                obb_from = child_pred_boxes[sym_from_th, :]\n",
        "                with torch.no_grad():\n",
        "                    reweight_from = get_surface_reweighting_batch(obb_from[:, 3:6], self.unit_cube.size(0))\n",
        "                pc_from = transform_pc_batch(self.unit_cube, obb_from)\n",
        "                sym_to_th = torch.tensor(sym_to, dtype=torch.long, device=self.conf.device)\n",
        "                obb_to = child_pred_boxes[sym_to_th, :]\n",
        "                with torch.no_grad():\n",
        "                    reweight_to = get_surface_reweighting_batch(obb_to[:, 3:6], self.unit_cube.size(0))\n",
        "                pc_to = transform_pc_batch(self.unit_cube, obb_to)\n",
        "                sym_mat_th = torch.cat(sym_mat, dim=0)\n",
        "                transformed_pc_from = pc_from.matmul(torch.transpose(sym_mat_th[:, :, :3], 1, 2)) + \\\n",
        "                        sym_mat_th[:, :, 3].unsqueeze(dim=1).repeat(1, pc_from.size(1), 1)\n",
        "                dist1, dist2 = self.chamferLoss(transformed_pc_from, pc_to)\n",
        "                loss1 = (dist1 * reweight_from).sum(dim=1) / (reweight_from.sum(dim=1) + 1e-12)\n",
        "                loss2 = (dist2 * reweight_to).sum(dim=1) / (reweight_to.sum(dim=1) + 1e-12)\n",
        "                loss = loss1 + loss2\n",
        "                sym_loss = loss.sum()\n",
        "\n",
        "            adj_loss = 0\n",
        "            if len(adj_from) > 0:\n",
        "                adj_from_th = torch.tensor(adj_from, dtype=torch.long, device=self.conf.device)\n",
        "                obb_from = child_pred_boxes[adj_from_th, :]\n",
        "                pc_from = transform_pc_batch(self.unit_cube, obb_from)\n",
        "                adj_to_th = torch.tensor(adj_to, dtype=torch.long, device=self.conf.device)\n",
        "                obb_to = child_pred_boxes[adj_to_th, :]\n",
        "                pc_to = transform_pc_batch(self.unit_cube, obb_to)\n",
        "                dist1, dist2 = self.chamferLoss(pc_from, pc_to)\n",
        "                loss = (dist1.min(dim=1)[0] + dist2.min(dim=1)[0])\n",
        "                adj_loss = loss.sum()\n",
        "\n",
        "            # call children + aggregate losses\n",
        "            pred2allboxes = dict(); pred2allleafboxes = dict();\n",
        "            for i in range(len(matched_gt_idx)):\n",
        "                child_losses, child_all_boxes, child_all_leaf_boxes = self.node_recon_loss(\n",
        "                    child_feats[:, matched_pred_idx[i], :], gt_node.children[matched_gt_idx[i]])\n",
        "                pred2allboxes[matched_pred_idx[i]] = child_all_boxes\n",
        "                pred2allleafboxes[matched_pred_idx[i]] = child_all_leaf_boxes\n",
        "                all_boxes.append(child_all_boxes)\n",
        "                all_leaf_boxes.append(child_all_leaf_boxes)\n",
        "                box_loss = box_loss + child_losses['box']\n",
        "                anchor_loss = anchor_loss + child_losses['anchor']\n",
        "                is_leaf_loss = is_leaf_loss + child_losses['leaf']\n",
        "                child_exists_loss = child_exists_loss + child_losses['exists']\n",
        "                semantic_loss = semantic_loss + child_losses['semantic']\n",
        "                edge_exists_loss = edge_exists_loss + child_losses['edge_exists']\n",
        "                sym_loss = sym_loss + child_losses['sym']\n",
        "                adj_loss = adj_loss + child_losses['adj']\n",
        "\n",
        "            # for sym-edges, train subtree to be symmetric\n",
        "            for i in range(len(sym_from)):\n",
        "                s1 = pred2allboxes[sym_from[i]].size(0)\n",
        "                s2 = pred2allboxes[sym_to[i]].size(0)\n",
        "                if s1 > 1 and s2 > 1:\n",
        "                    obbs_from = pred2allboxes[sym_from[i]][1:, :]\n",
        "                    obbs_to = pred2allboxes[sym_to[i]][1:, :]\n",
        "                    pc_from = transform_pc_batch(self.unit_cube, obbs_from).view(-1, 3)\n",
        "                    pc_to = transform_pc_batch(self.unit_cube, obbs_to).view(-1, 3)\n",
        "                    transformed_pc_from = pc_from.matmul(torch.transpose(sym_mat[i][0, :, :3], 0, 1)) + \\\n",
        "                            sym_mat[i][0, :, 3].unsqueeze(dim=0).repeat(pc_from.size(0), 1)\n",
        "                    dist1, dist2 = self.chamferLoss(transformed_pc_from.view(1, -1, 3), pc_to.view(1, -1, 3))\n",
        "                    sym_loss += (dist1.mean() + dist2.mean()) * (s1 + s2) / 2\n",
        "\n",
        "            # for adj-edges, train leaf-nodes in subtrees to be adjacent\n",
        "            for i in range(len(adj_from)):\n",
        "                if pred2allboxes[adj_from[i]].size(0) > pred2allleafboxes[adj_from[i]].size(0) \\\n",
        "                        or pred2allboxes[adj_to[i]].size(0) > pred2allleafboxes[adj_to[i]].size(0):\n",
        "                    obbs_from = pred2allleafboxes[adj_from[i]]\n",
        "                    obbs_to = pred2allleafboxes[adj_to[i]]\n",
        "                    pc_from = transform_pc_batch(self.unit_cube, obbs_from).view(1, -1, 3)\n",
        "                    pc_to = transform_pc_batch(self.unit_cube, obbs_to).view(1, -1, 3)\n",
        "                    dist1, dist2 = self.chamferLoss(pc_from, pc_to)\n",
        "                    adj_loss += dist1.min() + dist2.min()\n",
        "\n",
        "            return {'box': box_loss + unused_box_loss, 'leaf': is_leaf_loss, 'anchor': anchor_loss,\n",
        "                    'exists': child_exists_loss, 'semantic': semantic_loss,\n",
        "                    'edge_exists': edge_exists_loss, 'sym': sym_loss, 'adj': adj_loss}, \\\n",
        "                            torch.cat(all_boxes, dim=0), torch.cat(all_leaf_boxes, dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFAa3SewDIAQ"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUD1Z9ayDHaX"
      },
      "outputs": [],
      "source": [
        "# python ./train_box.py \\\n",
        "#   --exp_name 'box_ae_chair' \\\n",
        "#   --category 'Chair' \\\n",
        "#   --data_path '/content/structurenet/data/partnetdata/chair_hier' \\\n",
        "#   --train_dataset 'train_no_other_less_than_10_parts.txt' \\\n",
        "#   --val_dataset 'val_no_other_less_than_10_parts.txt' \\\n",
        "#   --epochs 200 \\\n",
        "#   --model_version 'model_box' \\\n",
        "#   --non_variational"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZeGh7gkFhJn"
      },
      "outputs": [],
      "source": [
        "# if __name__ == '__main__':\n",
        "#     sys.setrecursionlimit(5000) # this code uses recursion a lot for code simplicity\n",
        "\n",
        "#     parser = ArgumentParser()\n",
        "#     parser = add_train_vae_args(parser)\n",
        "#     config = parser.parse_args()\n",
        "\n",
        "#     Tree.load_category_info(config.category)\n",
        "#     train(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRHmcx0dDf95"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import sys\n",
        "import shutil\n",
        "import random\n",
        "from time import strftime\n",
        "from argparse import ArgumentParser\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import utils\n",
        "import importlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGG_UyEOEZpI"
      },
      "outputs": [],
      "source": [
        "# Use 1-4 CPU threads to train.\n",
        "# Don't use too many CPU threads, which will slow down the training.\n",
        "torch.set_num_threads(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPXxJ1ykXHcL"
      },
      "source": [
        "#Helper function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OapezNE0Qpkr"
      },
      "source": [
        "## Tree class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWMUvMzEWhUL"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils import data\n",
        "from pyquaternion import Quaternion\n",
        "from sklearn.decomposition import PCA\n",
        "from collections import namedtuple\n",
        "from utils import one_hot\n",
        "import trimesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhZO95hMZ53L"
      },
      "outputs": [],
      "source": [
        "\n",
        "# def quaternion_from_matrix(matrix, rtol=1e-5, atol=1e-8):\n",
        "#     def custom_from_matrix(cls, matrix, **kwargs):\n",
        "#         return Quaternion._from_matrix(cls, matrix, rtol=rtol, atol=atol)\n",
        "\n",
        "#     original_from_matrix = Quaternion._from_matrix\n",
        "#     Quaternion._from_matrix = custom_from_matrix\n",
        "\n",
        "#     q = Quaternion(matrix=matrix)\n",
        "\n",
        "#     # Restore the original method after creating the quaternion\n",
        "#     Quaternion._from_matrix = original_from_matrix\n",
        "\n",
        "#     return q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYgFiuNSb33T"
      },
      "outputs": [],
      "source": [
        "\n",
        "def rotmat_to_quaternion(rotmat, rtol=1e-5, atol=1e-8):\n",
        "    q = np.empty(4)\n",
        "    t = np.trace(rotmat)\n",
        "    if t > 0.0:\n",
        "        r = np.sqrt(1.0 + t)\n",
        "        s = 0.5 / r\n",
        "        q[0] = 0.5 * r\n",
        "        q[1] = (rotmat[2, 1] - rotmat[1, 2]) * s\n",
        "        q[2] = (rotmat[0, 2] - rotmat[2, 0]) * s\n",
        "        q[3] = (rotmat[1, 0] - rotmat[0, 1]) * s\n",
        "    else:\n",
        "        i = np.argmax(np.diagonal(rotmat))\n",
        "        j = (i + 1) % 3\n",
        "        k = (j + 1) % 3\n",
        "        r = np.sqrt(1.0 + rotmat[i, i] - rotmat[j, j] - rotmat[k, k])\n",
        "        s = 0.5 / r\n",
        "        q[i + 1] = 0.5 * r\n",
        "        q[j + 1] = (rotmat[i, j] + rotmat[j, i]) * s\n",
        "        q[k + 1] = (rotmat[i, k] + rotmat[k, i]) * s\n",
        "        q[0] = (rotmat[k, j] - rotmat[j, k]) * s\n",
        "    return q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_DdPj62Qskr"
      },
      "outputs": [],
      "source": [
        "class Tree(object):\n",
        "\n",
        "    # global object category information\n",
        "    part_name2id = dict()\n",
        "    part_id2name = dict()\n",
        "    part_name2cids = dict()\n",
        "    part_non_leaf_sem_names = []\n",
        "    num_sem = None\n",
        "    root_sem = None\n",
        "\n",
        "    @ staticmethod\n",
        "    def load_category_info(cat):\n",
        "        path = os.path.join('./stats/part_semantics/', cat+'.txt')\n",
        "        with open(path, 'r') as fin:\n",
        "\n",
        "            for l in fin.readlines():\n",
        "                x, y, _ = l.rstrip().split()\n",
        "                x = int(x)\n",
        "                Tree.part_name2id[y] = x\n",
        "                Tree.part_id2name[x] = y\n",
        "                Tree.part_name2cids[y] = []\n",
        "                if '/' in y:\n",
        "                    Tree.part_name2cids['/'.join(y.split('/')[:-1])].append(x)\n",
        "        Tree.num_sem = len(Tree.part_name2id) + 1\n",
        "        for k in Tree.part_name2cids:\n",
        "            Tree.part_name2cids[k] = np.array(Tree.part_name2cids[k], dtype=np.int32)\n",
        "            if len(Tree.part_name2cids[k]) > 0:\n",
        "                Tree.part_non_leaf_sem_names.append(k)\n",
        "        Tree.root_sem = Tree.part_id2name[1]\n",
        "        # print(\"Tree.num_sem:\", Tree.num_sem)\n",
        "        # print(\"Tree.part_name2id:\", Tree.part_name2id)\n",
        "        # print(\"Tree.part_id2name:\", Tree.part_id2name)\n",
        "\n",
        "\n",
        "    # store a part node in the tree\n",
        "    class Node(object):\n",
        "\n",
        "        def __init__(self, part_id=0, is_leaf=False, box=None, label=None, children=None, edges=None, full_label=None, geo=None, geo_feat=None):\n",
        "            self.is_leaf = is_leaf          # store True if the part is a leaf node\n",
        "            self.part_id = part_id          # part_id in result_after_merging.json of PartNet\n",
        "            self.box = box                  # box parameter for all nodes\n",
        "            self.geo = geo                  # 1 x 1000 x 3 point cloud\n",
        "            self.geo_feat = geo_feat        # 1 x 100 geometry feature\n",
        "            self.label = label              # node semantic label at the current level\n",
        "            self.full_label = full_label    # node semantic label from root (separated by slash)\n",
        "            self.children = [] if children is None else children\n",
        "                                            # all of its children nodes; each entry is a Node instance\n",
        "            self.edges = [] if edges is None else edges\n",
        "                                            # all of its children relationships;\n",
        "                                            # each entry is a tuple <part_a, part_b, type, params, dist>\n",
        "            \"\"\"\n",
        "                Here defines the edges format:\n",
        "                    part_a, part_b:\n",
        "                        Values are the order in self.children (e.g. 0, 1, 2, 3, ...).\n",
        "                        This is an directional edge for A->B.\n",
        "                        If an edge is commutative, you may need to manually specify a B->A edge.\n",
        "                        For example, an ADJ edge is only shown A->B,\n",
        "                        there is no edge B->A in the json file.\n",
        "                    type:\n",
        "                        Four types considered in StructureNet: ADJ, ROT_SYM, TRANS_SYM, REF_SYM.\n",
        "                    params:\n",
        "                        There is no params field for ADJ edge;\n",
        "                        For ROT_SYM edge, 0-2 pivot point, 3-5 axis unit direction, 6 radian rotation angle;\n",
        "                        For TRANS_SYM edge, 0-2 translation vector;\n",
        "                        For REF_SYM edge, 0-2 the middle point of the segment that connects the two box centers,\n",
        "                            3-5 unit normal direction of the reflection plane.\n",
        "                    dist:\n",
        "                        For ADJ edge, it's the closest distance between two parts;\n",
        "                        For SYM edge, it's the chamfer distance after matching part B to part A.\n",
        "            \"\"\"\n",
        "\n",
        "        def get_semantic_id(self):\n",
        "            return Tree.part_name2id[self.full_label]\n",
        "\n",
        "        def get_semantic_one_hot(self):\n",
        "            out = np.zeros((1, Tree.num_sem), dtype=np.float32)\n",
        "            out[0, Tree.part_name2id[self.full_label]] = 1\n",
        "            return torch.tensor(out, dtype=torch.float32).to(device=self.box.device)\n",
        "\n",
        "\n",
        "\n",
        "        def get_box_quat(self):\n",
        "            box = self.box.cpu().numpy().squeeze()\n",
        "            center = box[:3]\n",
        "            size = box[3:6]\n",
        "            xdir = box[6:9]\n",
        "            xdir /= np.linalg.norm(xdir)\n",
        "            ydir = box[9:]\n",
        "            ydir /= np.linalg.norm(ydir)\n",
        "            zdir = np.cross(xdir, ydir)\n",
        "            zdir /= np.linalg.norm(zdir)\n",
        "            rotmat = np.vstack([xdir, ydir, zdir]).T\n",
        "            # def gram_schmidt(mat):\n",
        "            #   result = np.zeros_like(mat)\n",
        "            #   for i in range(mat.shape[1]):\n",
        "            #       v = mat[:, i]\n",
        "            #       for j in range(i):\n",
        "            #           v -= np.dot(mat[:, i], result[:, j]) * result[:, j]\n",
        "            #       v /= np.linalg.norm(v)\n",
        "            #       result[:, i] = v\n",
        "            #   return result\n",
        "            # print(\"Before orthogonalization:\")\n",
        "            # print(\"Rotmat:\", rotmat)\n",
        "            # print(\"Rotmat * Rotmat.T:\", np.dot(rotmat, rotmat.T))\n",
        "            # print(\"Det(Rotmat):\", np.linalg.det(rotmat))\n",
        "\n",
        "            # rotmat = gram_schmidt(rotmat)\n",
        "\n",
        "            # print(\"\\nAfter orthogonalization:\")\n",
        "            # print(\"Rotmat:\", rotmat)\n",
        "            # print(\"Rotmat * Rotmat.T:\", np.dot(rotmat, rotmat.T))\n",
        "            # print(\"Det(Rotmat):\", np.linalg.det(rotmat))\n",
        "            rounded_rotmat = np.round(rotmat, decimals=8)\n",
        "            quat = rotmat_to_quaternion(rounded_rotmat)\n",
        "            box_quat = np.hstack([center, size, quat]).astype(np.float32)\n",
        "            return torch.from_numpy(box_quat).view(1, -1).to(device=self.box.device)\n",
        "\n",
        "        def set_from_box_quat(self, box_quat):\n",
        "            box_quat = box_quat.cpu().numpy().squeeze()\n",
        "            center = box_quat[:3]\n",
        "            size = box_quat[3:6]\n",
        "            q = Quaternion(box_quat[6], box_quat[7], box_quat[8], box_quat[9])\n",
        "            rotmat = q.rotation_matrix\n",
        "            box = np.hstack([center, size, rotmat[:, 0].flatten(), rotmat[:, 1].flatten()]).astype(np.float32)\n",
        "            self.box = torch.from_numpy(box).view(1, -1)\n",
        "\n",
        "        def to(self, device):\n",
        "            if self.box is not None:\n",
        "                self.box = self.box.to(device)\n",
        "            for edge in self.edges:\n",
        "                if 'params' in edge:\n",
        "                    edge['params'].to(device)\n",
        "            if self.geo is not None:\n",
        "                self.geo = self.geo.to(device)\n",
        "\n",
        "            for child_node in self.children:\n",
        "                child_node.to(device)\n",
        "\n",
        "            return self\n",
        "\n",
        "        def _to_str(self, level, pid, detailed=False):\n",
        "            out_str = '  |'*(level-1) + '  ├'*(level > 0) + str(pid) + ' ' + self.label + (' [LEAF] ' if self.is_leaf else '    ') + '{' + str(self.part_id) + '}'\n",
        "            if detailed:\n",
        "                out_str += 'Box('+';'.join([str(item) for item in self.box.numpy()])+')\\n'\n",
        "            else:\n",
        "                out_str += '\\n'\n",
        "\n",
        "            if len(self.children) > 0:\n",
        "                for idx, child in enumerate(self.children):\n",
        "                    out_str += child._to_str(level+1, idx)\n",
        "\n",
        "            if detailed and len(self.edges) > 0:\n",
        "                for edge in self.edges:\n",
        "                    if 'params' in edge:\n",
        "                        edge = edge.copy() # so the original parameters don't get changed\n",
        "                        edge['params'] = edge['params'].cpu().numpy()\n",
        "                    out_str += '  |'*(level) + '  ├' + 'Edge(' + str(edge) + ')\\n'\n",
        "\n",
        "            return out_str\n",
        "\n",
        "        def __str__(self):\n",
        "            return self._to_str(0, 0)\n",
        "\n",
        "        def depth_first_traversal(self):\n",
        "            nodes = []\n",
        "\n",
        "            stack = [self]\n",
        "            while len(stack) > 0:\n",
        "                node = stack.pop()\n",
        "                nodes.append(node)\n",
        "\n",
        "                stack.extend(reversed(node.children))\n",
        "\n",
        "            return nodes\n",
        "\n",
        "        def child_adjacency(self, typed=False, max_children=None):\n",
        "            if max_children is None:\n",
        "                adj = torch.zeros(len(self.children), len(self.children))\n",
        "            else:\n",
        "                adj = torch.zeros(max_children, max_children)\n",
        "\n",
        "            if typed:\n",
        "                edge_types = ['ADJ', 'ROT_SYM', 'TRANS_SYM', 'REF_SYM']\n",
        "\n",
        "            for edge in self.edges:\n",
        "                if typed:\n",
        "                    edge_type_index = edge_types.index(edge['type'])\n",
        "                    adj[edge['part_a'], edge['part_b']] = edge_type_index\n",
        "                    adj[edge['part_b'], edge['part_a']] = edge_type_index\n",
        "                else:\n",
        "                    adj[edge['part_a'], edge['part_b']] = 1\n",
        "                    adj[edge['part_b'], edge['part_a']] = 1\n",
        "\n",
        "            return adj\n",
        "\n",
        "        def geos(self, leafs_only=True):\n",
        "            nodes = list(self.depth_first_traversal())\n",
        "            out_geos = []; out_nodes = [];\n",
        "            for node in nodes:\n",
        "                if not leafs_only or node.is_leaf:\n",
        "                    out_geos.append(node.geo)\n",
        "                    out_nodes.append(node)\n",
        "            return out_geos, out_nodes\n",
        "\n",
        "        def boxes(self, per_node=False, leafs_only=False):\n",
        "            nodes = list(reversed(self.depth_first_traversal()))\n",
        "            node_boxesets = []\n",
        "            boxes_stack = []\n",
        "            for node in nodes:\n",
        "                node_boxes = []\n",
        "                for i in range(len(node.children)):\n",
        "                    node_boxes = boxes_stack.pop() + node_boxes\n",
        "\n",
        "                if node.box is not None and (not leafs_only or node.is_leaf):\n",
        "                    node_boxes.append(node.box)\n",
        "\n",
        "                if per_node:\n",
        "                    node_boxesets.append(node_boxes)\n",
        "\n",
        "                boxes_stack.append(node_boxes)\n",
        "\n",
        "            assert len(boxes_stack) == 1\n",
        "\n",
        "            if per_node:\n",
        "                return node_boxesets, list(nodes)\n",
        "            else:\n",
        "                boxes = boxes_stack[0]\n",
        "                return boxes\n",
        "\n",
        "        def graph(self, leafs_only=False):\n",
        "            part_boxes = []\n",
        "            part_geos = []\n",
        "            edges = []\n",
        "            part_ids = []\n",
        "            part_sems = []\n",
        "\n",
        "            nodes = list(reversed(self.depth_first_traversal()))\n",
        "\n",
        "            box_index_offset = 0\n",
        "            for node in nodes:\n",
        "                child_count = 0\n",
        "                box_idx = {}\n",
        "                for i, child in enumerate(node.children):\n",
        "                    if leafs_only and not child.is_leaf:\n",
        "                        continue\n",
        "\n",
        "                    part_boxes.append(child.box)\n",
        "                    part_geos.append(child.geo)\n",
        "                    part_ids.append(child.part_id)\n",
        "                    part_sems.append(child.full_label)\n",
        "\n",
        "                    box_idx[i] = child_count+box_index_offset\n",
        "                    child_count += 1\n",
        "\n",
        "                for edge in node.edges:\n",
        "                    if leafs_only and not (\n",
        "                            node.children[edge['part_a']].is_leaf and\n",
        "                            node.children[edge['part_b']].is_leaf):\n",
        "                        continue\n",
        "                    edges.append(edge.copy())\n",
        "                    edges[-1]['part_a'] = box_idx[edges[-1]['part_a']]\n",
        "                    edges[-1]['part_b'] = box_idx[edges[-1]['part_b']]\n",
        "\n",
        "                box_index_offset += child_count\n",
        "\n",
        "            return part_boxes, part_geos, edges, part_ids, part_sems\n",
        "\n",
        "        def edge_tensors(self, edge_types, device, type_onehot=True):\n",
        "            num_edges = len(self.edges)\n",
        "\n",
        "            # get directed edge indices in both directions as tensor\n",
        "            edge_indices = torch.tensor(\n",
        "                [[e['part_a'], e['part_b']] for e in self.edges] + [[e['part_b'], e['part_a']] for e in self.edges],\n",
        "                device=device, dtype=torch.long).view(1, num_edges*2, 2)\n",
        "\n",
        "            # get edge type as tensor\n",
        "            edge_type = torch.tensor([edge_types.index(edge['type']) for edge in self.edges], device=device, dtype=torch.long)\n",
        "            if type_onehot:\n",
        "                edge_type = one_hot(inp=edge_type, label_count=len(edge_types)).transpose(0, 1).view(1, num_edges, len(edge_types)).to(dtype=torch.float32)\n",
        "            else:\n",
        "                edge_type = edge_type.view(1, num_edges)\n",
        "            edge_type = torch.cat([edge_type, edge_type], dim=1) # add edges in other direction (symmetric adjacency)\n",
        "\n",
        "            return edge_type, edge_indices\n",
        "\n",
        "        def get_subtree_edge_count(self):\n",
        "            cnt = 0\n",
        "            if self.children is not None:\n",
        "                for cnode in self.children:\n",
        "                    cnt += cnode.get_subtree_edge_count()\n",
        "            if self.edges is not None:\n",
        "                cnt += len(self.edges)\n",
        "            return cnt\n",
        "\n",
        "\n",
        "    # functions for class Tree\n",
        "    def __init__(self, root):\n",
        "        self.root = root\n",
        "\n",
        "    def to(self, device):\n",
        "        self.root = self.root.to(device)\n",
        "        return self\n",
        "\n",
        "    def __str__(self):\n",
        "        return str(self.root)\n",
        "\n",
        "    def depth_first_traversal(self):\n",
        "        return self.root.depth_first_traversal()\n",
        "\n",
        "    def boxes(self, per_node=False, leafs_only=False):\n",
        "        return self.root.boxes(per_node=per_node, leafs_only=leafs_only)\n",
        "\n",
        "    def graph(self, leafs_only=False):\n",
        "        return self.root.graph(leafs_only=leafs_only)\n",
        "\n",
        "    def free(self):\n",
        "        for node in self.depth_first_traversal():\n",
        "            del node.geo\n",
        "            del node.geo_feat\n",
        "            del node.box\n",
        "            del node\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rApwVkccWVsT"
      },
      "source": [
        "## PartNet class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpOt6a8lWX5i"
      },
      "outputs": [],
      "source": [
        "class PartNetDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, root, object_list, data_features, load_geo=False):\n",
        "        self.root = root\n",
        "        self.data_features = data_features\n",
        "        self.load_geo = load_geo\n",
        "\n",
        "        if isinstance(object_list, str):\n",
        "            with open(os.path.join(self.root, object_list), 'r') as f:\n",
        "                self.object_names = [item.rstrip() for item in f.readlines()]\n",
        "        else:\n",
        "            self.object_names = object_list\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if 'object' in self.data_features:\n",
        "            obj = self.load_object(os.path.join(self.root, self.object_names[index]+'.json'), \\\n",
        "                    load_geo=self.load_geo)\n",
        "\n",
        "        data_feats = ()\n",
        "        for feat in self.data_features:\n",
        "            if feat == 'object':\n",
        "                data_feats = data_feats + (obj,)\n",
        "            elif feat == 'name':\n",
        "                data_feats = data_feats + (self.object_names[index],)\n",
        "            else:\n",
        "                assert False, 'ERROR: unknow feat type %s!' % feat\n",
        "\n",
        "        return data_feats\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.object_names)\n",
        "\n",
        "    def get_anno_id(self, anno_id):\n",
        "        obj = self.load_object(os.path.join(self.root, anno_id+'.json'), \\\n",
        "                load_geo=self.load_geo)\n",
        "        return obj\n",
        "\n",
        "    @staticmethod\n",
        "    def load_object(fn, load_geo=False):\n",
        "        if load_geo:\n",
        "            geo_fn = fn.replace('_hier', '_geo').replace('json', 'npz')\n",
        "            geo_data = np.load(geo_fn)\n",
        "\n",
        "        with open(fn, 'r') as f:\n",
        "            root_json = json.load(f)\n",
        "\n",
        "        # create a virtual parent node of the root node and add it to the stack\n",
        "        StackElement = namedtuple('StackElement', ['node_json', 'parent', 'parent_child_idx'])\n",
        "        stack = [StackElement(node_json=root_json, parent=None, parent_child_idx=None)]\n",
        "\n",
        "        root = None\n",
        "        # traverse the tree, converting each node json to a Node instance\n",
        "        while len(stack) > 0:\n",
        "            stack_elm = stack.pop()\n",
        "\n",
        "            parent = stack_elm.parent\n",
        "            parent_child_idx = stack_elm.parent_child_idx\n",
        "            node_json = stack_elm.node_json\n",
        "\n",
        "            node = Tree.Node(\n",
        "                part_id=node_json['id'],\n",
        "                is_leaf=('children' not in node_json),\n",
        "                label=node_json['label'])\n",
        "\n",
        "            if 'geo' in node_json.keys():\n",
        "                node.geo = torch.tensor(np.array(node_json['geo']), dtype=torch.float32).view(1, -1, 3)\n",
        "\n",
        "            if load_geo:\n",
        "                node.geo = torch.tensor(geo_data['parts'][node_json['id']], dtype=torch.float32).view(1, -1, 3)\n",
        "\n",
        "            if 'box' in node_json:\n",
        "                node.box = torch.from_numpy(np.array(node_json['box'])).to(dtype=torch.float32)\n",
        "\n",
        "            if 'children' in node_json:\n",
        "                for ci, child in enumerate(node_json['children']):\n",
        "                    stack.append(StackElement(node_json=node_json['children'][ci], parent=node, parent_child_idx=ci))\n",
        "\n",
        "            if 'edges' in node_json:\n",
        "                for edge in node_json['edges']:\n",
        "                    if 'params' in edge:\n",
        "                        edge['params'] = torch.from_numpy(np.array(edge['params'])).to(dtype=torch.float32)\n",
        "                    node.edges.append(edge)\n",
        "\n",
        "            if parent is None:\n",
        "                root = node\n",
        "                root.full_label = root.label\n",
        "            else:\n",
        "                if len(parent.children) <= parent_child_idx:\n",
        "                    parent.children.extend([None] * (parent_child_idx+1-len(parent.children)))\n",
        "                parent.children[parent_child_idx] = node\n",
        "                node.full_label = parent.full_label + '/' + node.label\n",
        "\n",
        "        obj = Tree(root=root)\n",
        "\n",
        "        return obj\n",
        "\n",
        "    @staticmethod\n",
        "    def save_object(obj, fn):\n",
        "\n",
        "        # create a virtual parent node of the root node and add it to the stack\n",
        "        StackElement = namedtuple('StackElement', ['node', 'parent_json', 'parent_child_idx'])\n",
        "        stack = [StackElement(node=obj.root, parent_json=None, parent_child_idx=None)]\n",
        "\n",
        "        obj_json = None\n",
        "\n",
        "        # traverse the tree, converting child nodes of each node to json\n",
        "        while len(stack) > 0:\n",
        "            stack_elm = stack.pop()\n",
        "\n",
        "            parent_json = stack_elm.parent_json\n",
        "            parent_child_idx = stack_elm.parent_child_idx\n",
        "            node = stack_elm.node\n",
        "\n",
        "            node_json = {\n",
        "                'id': node.part_id,\n",
        "                'label': f'{node.label if node.label is not None else \"\"}'}\n",
        "\n",
        "            if node.geo is not None:\n",
        "                node_json['geo'] = node.geo.cpu().numpy().reshape(-1).tolist()\n",
        "\n",
        "            if node.box is not None:\n",
        "                node_json['box'] = node.box.cpu().numpy().reshape(-1).tolist()\n",
        "\n",
        "            if len(node.children) > 0:\n",
        "                node_json['children'] = []\n",
        "            for child in node.children:\n",
        "                node_json['children'].append(None)\n",
        "                stack.append(StackElement(node=child, parent_json=node_json, parent_child_idx=len(node_json['children'])-1))\n",
        "\n",
        "            if len(node.edges) > 0:\n",
        "                node_json['edges'] = []\n",
        "            for edge in node.edges:\n",
        "                node_json['edges'].append(edge)\n",
        "                if 'params' in edge:\n",
        "                    node_json['edges'][-1]['params'] = node_json['edges'][-1]['params'].cpu().numpy().reshape(-1).tolist()\n",
        "\n",
        "            if parent_json is None:\n",
        "                obj_json = node_json\n",
        "            else:\n",
        "                parent_json['children'][parent_child_idx] = node_json\n",
        "\n",
        "        with open(fn, 'w') as f:\n",
        "            json.dump(obj_json, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aii3QMPdAENB"
      },
      "source": [
        "##Pasrse Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3LZbb-wGEXB"
      },
      "outputs": [],
      "source": [
        "def add_base_args(parser):\n",
        "    parser.add_argument('--exp_name', type=str, default='no_name', help='name of the training run')\n",
        "    parser.add_argument('--category', type=str, default='Chair', help='object category')\n",
        "    parser.add_argument('--device', type=str, default='cuda:0', help='cpu or cuda:x for using cuda on GPU number x')\n",
        "    parser.add_argument('--seed', type=int, default=3124256514, help='random seed (for reproducibility)')\n",
        "\n",
        "    return parser\n",
        "\n",
        "def add_model_args(parser):\n",
        "    parser.add_argument('--model_path', type=str, default='./data/models')\n",
        "\n",
        "    return parser\n",
        "\n",
        "def add_data_args(parser):\n",
        "    parser.add_argument('--data_path', type=str, default='')\n",
        "    parser.add_argument('--train_dataset', type=str, default='train.txt', help='file name for the list of object names for training')\n",
        "    parser.add_argument('--edge_types', type=str, nargs='*', default=['ADJ', 'ROT_SYM', 'TRANS_SYM', 'REF_SYM'], help='list of possible edge types')\n",
        "\n",
        "    return parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqnZNBRoF85q"
      },
      "outputs": [],
      "source": [
        "def add_train_vae_args(parser):\n",
        "    parser = add_base_args(parser)\n",
        "    parser = add_model_args(parser)\n",
        "    parser = add_data_args(parser)\n",
        "\n",
        "    # validation dataset\n",
        "    parser.add_argument('--val_dataset', type=str, default='val.txt', help='file name for the list of object names for validation')\n",
        "\n",
        "    # model hyperparameters\n",
        "    parser.add_argument('--geo_feat_size', type=int, default=100)\n",
        "    parser.add_argument('--feature_size', type=int, default=256)\n",
        "    parser.add_argument('--hidden_size', type=int, default=256)\n",
        "    parser.add_argument('--num_point', type=int, default=1000)\n",
        "    parser.add_argument('--load_geo', action='store_true', default=False)\n",
        "    parser.add_argument('--max_tree_depth', type=int, default=100, help='maximum depth of generated object trees')\n",
        "    parser.add_argument('--max_child_num', type=int, default=10, help='maximum number of children per parent')\n",
        "    parser.add_argument('--node_symmetric_type', type=str, default='max', help='node pooling type')\n",
        "    parser.add_argument('--edge_symmetric_type', type=str, default='avg', help='edge pooling type')\n",
        "    parser.add_argument('--num_gnn_iterations', type=int, default=2, help='number of message passing iterations for the GNN encoding')\n",
        "    parser.add_argument('--num_dec_gnn_iterations', type=int, default=2, help='number of message passing iterations for the GNN decoding')\n",
        "    parser.add_argument('--model_version', type=str, default='model', help='model file name')\n",
        "\n",
        "    # training parameters\n",
        "    parser.add_argument('--epochs', type=int, default=200)\n",
        "    parser.add_argument('--batch_size', type=int, default=32)\n",
        "    parser.add_argument('--lr', type=float, default=.001)\n",
        "    parser.add_argument('--weight_decay', type=float, default=1e-5)\n",
        "    parser.add_argument('--lr_decay_by', type=float, default=0.9)\n",
        "    parser.add_argument('--lr_decay_every', type=float, default=500)\n",
        "    parser.add_argument('--non_variational', action='store_true', default=False, help='make the variational autoencoder non-variational')\n",
        "\n",
        "    # loss weights\n",
        "    parser.add_argument('--loss_weight_geo', type=float, default=2.0, help='weight for the geo recon loss')\n",
        "    parser.add_argument('--loss_weight_latent', type=float, default=20.0, help='weight for the latent recon loss')\n",
        "    parser.add_argument('--loss_weight_center', type=float, default=20.0, help='weight for the center recon loss')\n",
        "    parser.add_argument('--loss_weight_scale', type=float, default=20.0, help='weight for the scale recon loss')\n",
        "    parser.add_argument('--loss_weight_sym', type=float, default=1.0, help='weight for the sym loss')\n",
        "    parser.add_argument('--loss_weight_adj', type=float, default=1.0, help='weight for the adj loss')\n",
        "    parser.add_argument('--loss_weight_kldiv', type=float, default=0.05, help='weight for the kl divergence loss')\n",
        "    parser.add_argument('--loss_weight_box', type=float, default=20.0, help='weight for the box reconstruction loss')\n",
        "    parser.add_argument('--loss_weight_anchor', type=float, default=10.0, help='weight for the anchor reconstruction loss')\n",
        "    parser.add_argument('--loss_weight_leaf', type=float, default=1.0, help='weight for the \"node is leaf\" reconstruction loss')\n",
        "    parser.add_argument('--loss_weight_exists', type=float, default=1.0, help='weight for the \"node exists\" reconstruction loss')\n",
        "    parser.add_argument('--loss_weight_semantic', type=float, default=0.1, help='weight for the semantic reconstruction loss')\n",
        "    parser.add_argument('--loss_weight_edge_exists', type=float, default=1.0, help='weight for the \"edge exists\" loss')\n",
        "\n",
        "    # logging\n",
        "    parser.add_argument('--log_path', type=str, default='./data/logs')\n",
        "    parser.add_argument('--no_tb_log', action='store_true', default=False)\n",
        "    parser.add_argument('--no_console_log', action='store_true', default=False)\n",
        "    parser.add_argument('--console_log_interval', type=int, default=3, help='number of optimization steps beween console log prints')\n",
        "    parser.add_argument('--checkpoint_interval', type=int, default=10, help='number of optimization steps beween checkpoints')\n",
        "\n",
        "    # load pretrained model (for pc exps)\n",
        "    parser.add_argument('--part_pc_exp_name', type=str, help='resume model exp name')\n",
        "    parser.add_argument('--part_pc_model_epoch', type=int, help='resume model epoch')\n",
        "\n",
        "    return parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyg_tU2wymmf"
      },
      "source": [
        "# Train Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoWiOucxLt50"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(models, model_names, dirname, epoch=None, optimizers=None, optimizer_names=None, strict=True):\n",
        "    print(dirname)\n",
        "    if len(models) != len(model_names) or (optimizers is not None and len(optimizers) != len(optimizer_names)):\n",
        "        raise ValueError('Number of models, model names, or optimizers does not match.')\n",
        "\n",
        "    for model, model_name in zip(models, model_names):\n",
        "        print(model_name)\n",
        "        filename = f'net_{model_name}.pth'\n",
        "        if epoch is not None:\n",
        "            filename = f'{epoch}_' + filename\n",
        "        print(filename)\n",
        "        model.load_state_dict(torch.load(os.path.join(dirname, filename)), strict=strict)\n",
        "\n",
        "    start_epoch = 0\n",
        "    if optimizers is not None:\n",
        "        filename = os.path.join(dirname, 'checkpt.pth')\n",
        "        if epoch is not None:\n",
        "            filename = f'{epoch}_' + filename\n",
        "        if os.path.exists(filename):\n",
        "            checkpt = torch.load(filename)\n",
        "            start_epoch = checkpt['epoch']\n",
        "            for opt, optimizer_name in zip(optimizers, optimizer_names):\n",
        "                opt.load_state_dict(checkpt[f'opt_{optimizer_name}'])\n",
        "            print(f'resuming from checkpoint {filename}')\n",
        "        else:\n",
        "            response = input(f'Checkpoint {filename} not found for resuming, refine saved models instead? (y/n) ')\n",
        "            if response != 'y':\n",
        "                sys.exit()\n",
        "\n",
        "    return start_epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9FRWH2ZEhxY"
      },
      "outputs": [],
      "source": [
        "def train(conf,load_check=False,last_epoch=None):\n",
        "    # load network model\n",
        "    # models = get_model_module(conf.model_version)\n",
        "\n",
        "    # check if training run already exists. If so, delete it.\n",
        "    if not load_check:\n",
        "      if os.path.exists(os.path.join(conf.log_path, conf.exp_name)) or \\\n",
        "        os.path.exists(os.path.join(conf.model_path, conf.exp_name)):\n",
        "          response = input('A training run named \"%s\" already exists, overwrite? (y/n) ' % (conf.exp_name))\n",
        "          if response != 'y':\n",
        "              sys.exit()\n",
        "      if os.path.exists(os.path.join(conf.log_path, conf.exp_name)):\n",
        "          shutil.rmtree(os.path.join(conf.log_path, conf.exp_name))\n",
        "      if os.path.exists(os.path.join(conf.model_path, conf.exp_name)):\n",
        "          shutil.rmtree(os.path.join(conf.model_path, conf.exp_name))\n",
        "\n",
        "      # create directories for this run\n",
        "      os.makedirs(os.path.join(conf.model_path, conf.exp_name))\n",
        "      os.makedirs(os.path.join(conf.log_path, conf.exp_name))\n",
        "\n",
        "    # file log\n",
        "    flog = open(os.path.join(conf.log_path, conf.exp_name, 'train.log'), 'w')\n",
        "\n",
        "    # set training device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Using device: {device}')\n",
        "    flog.write(f'Using device: {device}\\n')\n",
        "\n",
        "    # log the object category information\n",
        "    print(f'Object Category: {conf.category}')\n",
        "    flog.write(f'Object Category: {conf.category}\\n')\n",
        "\n",
        "    # control randomness\n",
        "    if conf.seed < 0:\n",
        "        conf.seed = random.randint(1, 10000)\n",
        "    print(\"Random Seed: %d\" % (conf.seed))\n",
        "    flog.write(f'Random Seed: {conf.seed}\\n')\n",
        "    random.seed(conf.seed)\n",
        "    np.random.seed(conf.seed)\n",
        "    torch.manual_seed(conf.seed)\n",
        "\n",
        "    # save config\n",
        "    torch.save(conf, os.path.join(conf.model_path, conf.exp_name, 'conf.pth'))\n",
        "\n",
        "    # create models\n",
        "    encoder = RecursiveEncoder(conf, variational=True, probabilistic=not conf.non_variational)\n",
        "    decoder = RecursiveDecoder(conf)\n",
        "    models = [encoder, decoder]\n",
        "    model_names = ['encoder', 'decoder']\n",
        "\n",
        "    # create optimizers\n",
        "    encoder_opt = torch.optim.Adam(encoder.parameters(), lr=conf.lr)\n",
        "    decoder_opt = torch.optim.Adam(decoder.parameters(), lr=conf.lr)\n",
        "    optimizers = [encoder_opt, decoder_opt]\n",
        "    optimizer_names = ['encoder', 'decoder']\n",
        "\n",
        "    # learning rate scheduler\n",
        "    encoder_scheduler = torch.optim.lr_scheduler.StepLR(encoder_opt, \\\n",
        "            step_size=conf.lr_decay_every, gamma=conf.lr_decay_by)\n",
        "    decoder_scheduler = torch.optim.lr_scheduler.StepLR(decoder_opt, \\\n",
        "            step_size=conf.lr_decay_every, gamma=conf.lr_decay_by)\n",
        "\n",
        "    start_epoch = 0\n",
        "\n",
        "    if load_check:\n",
        "      checkpoint_dir = os.path.join(conf.model_path, conf.exp_name)\n",
        "      if os.path.exists(checkpoint_dir):\n",
        "        checkpoint_file = os.path.join(checkpoint_dir, 'checkpt.pth')\n",
        "\n",
        "        if checkpoint_file:\n",
        "\n",
        "           _ = load_checkpoint(\n",
        "                        models=models, model_names=model_names, dirname=checkpoint_dir,\n",
        "                        epoch=last_epoch, optimizers=optimizers, optimizer_names=model_names)\n",
        "           start_epoch = last_epoch +1  # because the training will start from the next epoch\n",
        "           print(f'Checkpoint loaded. Resuming from epoch {start_epoch}.')\n",
        "\n",
        "    cur_epoch = start_epoch\n",
        "\n",
        "\n",
        "\n",
        "    # create training and validation datasets and data loaders\n",
        "    data_features = ['object']\n",
        "    train_dataset = PartNetDataset(conf.data_path, conf.train_dataset, data_features, \\\n",
        "            load_geo=conf.load_geo)\n",
        "    valdt_dataset = PartNetDataset(conf.data_path, conf.val_dataset, data_features, \\\n",
        "            load_geo=conf.load_geo)\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=conf.batch_size, \\\n",
        "            shuffle=True, collate_fn=utils.collate_feats)\n",
        "    valdt_dataloader = torch.utils.data.DataLoader(valdt_dataset, batch_size=conf.batch_size, \\\n",
        "            shuffle=True, collate_fn=utils.collate_feats)\n",
        "\n",
        "    # create logs\n",
        "    if not conf.no_console_log:\n",
        "        header = '     Time    Epoch     Dataset    Iteration    Progress(%)       LR       BoxLoss   StructLoss   EdgeExists  KLDivLoss   SymLoss    AdjLoss  AnchorLoss  TotalLoss'\n",
        "    if not conf.no_tb_log:\n",
        "        # https://github.com/lanpa/tensorboard-pytorch\n",
        "        from tensorboardX import SummaryWriter\n",
        "        train_writer = SummaryWriter(os.path.join(conf.log_path, conf.exp_name, 'train'))\n",
        "        valdt_writer = SummaryWriter(os.path.join(conf.log_path, conf.exp_name, 'val'))\n",
        "\n",
        "    # send parameters to device\n",
        "    for m in models:\n",
        "        m.to(device)\n",
        "    for o in optimizers:\n",
        "        utils.optimizer_to_device(o, device)\n",
        "\n",
        "    # start training\n",
        "    print(\"Starting training ...... \")\n",
        "    flog.write('Starting training ......\\n')\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    last_checkpoint_step = None\n",
        "    last_train_console_log_step, last_valdt_console_log_step = None, None\n",
        "    train_num_batch, valdt_num_batch = len(train_dataloader), len(valdt_dataloader)\n",
        "\n",
        "    # train for every epoch\n",
        "    for epoch in range(start_epoch, conf.epochs):\n",
        "        if not conf.no_console_log:\n",
        "            print(f'training run {conf.exp_name}')\n",
        "            flog.write(f'training run {conf.exp_name}\\n')\n",
        "            print(header)\n",
        "            flog.write(header+'\\n')\n",
        "\n",
        "        train_batches = enumerate(train_dataloader, 0)\n",
        "        valdt_batches = enumerate(valdt_dataloader, 0)\n",
        "\n",
        "        train_fraction_done, valdt_fraction_done = 0.0, 0.0\n",
        "        valdt_batch_ind = -1\n",
        "        cur_epoch = epoch\n",
        "        # train for every batch\n",
        "        for train_batch_ind, batch in train_batches:\n",
        "            train_fraction_done = (train_batch_ind + 1) / train_num_batch\n",
        "            train_step = epoch * train_num_batch + train_batch_ind\n",
        "\n",
        "            log_console = not conf.no_console_log and (last_train_console_log_step is None or \\\n",
        "                    train_step - last_train_console_log_step >= conf.console_log_interval)\n",
        "            if log_console:\n",
        "                last_train_console_log_step = train_step\n",
        "\n",
        "            # set models to training mode\n",
        "            for m in models:\n",
        "                m.train()\n",
        "\n",
        "            # forward pass (including logging)\n",
        "            total_loss = forward(\n",
        "                  batch=batch,\n",
        "                  data_features=data_features,\n",
        "                  encoder=encoder,\n",
        "                  decoder=decoder,\n",
        "                  device=device,\n",
        "                  conf=conf,\n",
        "                  is_valdt=False,\n",
        "                  step=train_step,\n",
        "                  epoch=epoch,\n",
        "                  batch_ind=train_batch_ind,\n",
        "                  num_batch=train_num_batch,\n",
        "                  start_time=start_time,\n",
        "                  log_console=log_console,\n",
        "                  log_tb=not conf.no_tb_log,\n",
        "                  tb_writer=train_writer,\n",
        "                  lr=encoder_opt.param_groups[0]['lr'],\n",
        "                  flog=flog)\n",
        "\n",
        "\n",
        "            # optimize one step\n",
        "            encoder_opt.zero_grad()\n",
        "            decoder_opt.zero_grad()\n",
        "            total_loss.backward()\n",
        "            encoder_opt.step()\n",
        "            decoder_opt.step()\n",
        "\n",
        "            encoder_scheduler.step()\n",
        "            decoder_scheduler.step()\n",
        "\n",
        "            # save checkpoint\n",
        "            with torch.no_grad():\n",
        "                if last_checkpoint_step is None or \\\n",
        "                        train_step - last_checkpoint_step >= conf.checkpoint_interval:\n",
        "                    print(\"Saving checkpoint ...... \", end='', flush=True)\n",
        "                    flog.write(\"Saving checkpoint ...... \")\n",
        "                    utils.save_checkpoint(\n",
        "                        models=models, model_names=model_names, dirname=os.path.join(conf.model_path, conf.exp_name),\n",
        "                        epoch=epoch, prepend_epoch=True, optimizers=optimizers, optimizer_names=model_names)\n",
        "                    print(\"DONE\")\n",
        "                    flog.write(\"DONE\\n\")\n",
        "                    last_checkpoint_step = train_step\n",
        "\n",
        "            # validate one batch\n",
        "            while valdt_fraction_done <= train_fraction_done and valdt_batch_ind+1 < valdt_num_batch:\n",
        "                valdt_batch_ind, batch = next(valdt_batches)\n",
        "\n",
        "                valdt_fraction_done = (valdt_batch_ind + 1) / valdt_num_batch\n",
        "                valdt_step = (epoch + valdt_fraction_done) * train_num_batch - 1\n",
        "\n",
        "                log_console = not conf.no_console_log and (last_valdt_console_log_step is None or \\\n",
        "                        valdt_step - last_valdt_console_log_step >= conf.console_log_interval)\n",
        "                if log_console:\n",
        "                    last_valdt_console_log_step = valdt_step\n",
        "\n",
        "                # set models to evaluation mode\n",
        "                for m in models:\n",
        "                    m.eval()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    # forward pass (including logging)\n",
        "                    __ = forward(\n",
        "                        batch=batch, data_features=data_features, encoder=encoder, decoder=decoder, device=device, conf=conf,\n",
        "                        is_valdt=True, step=valdt_step, epoch=epoch, batch_ind=valdt_batch_ind, num_batch=valdt_num_batch, start_time=start_time,\n",
        "                        log_console=log_console, log_tb=not conf.no_tb_log, tb_writer=valdt_writer,\n",
        "                        lr=encoder_opt.param_groups[0]['lr'], flog=flog)\n",
        "\n",
        "\n",
        "    # save the final models\n",
        "    print(\"Saving final checkpoint ...... \", end='', flush=True)\n",
        "    flog.write(\"Saving final checkpoint ...... \")\n",
        "    utils.save_checkpoint(\n",
        "        models=models, model_names=model_names, dirname=os.path.join(conf.model_path, conf.exp_name),\n",
        "        epoch=cur_epoch, prepend_epoch=False, optimizers=optimizers, optimizer_names=optimizer_names)\n",
        "    print(\"DONE\")\n",
        "    flog.write(\"DONE\\n\")\n",
        "\n",
        "    flog.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIUq3203GE-i"
      },
      "source": [
        "forward function is called during each iteration of the training and validation loop. It takes as input a batch of data, the encoder and decoder models, and various hyperparameters, and returns the total loss for the batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cv8cBchaFDGC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def forward(batch, data_features, encoder, decoder, device, conf,\n",
        "            is_valdt=False, step=None, epoch=None, batch_ind=0, num_batch=1, start_time=0,\n",
        "            log_console=False, log_tb=False, tb_writer=None, lr=None, flog=None):\n",
        "    objects = batch[data_features.index('object')]\n",
        "\n",
        "    losses = {\n",
        "        'box': torch.zeros(1, device=device),\n",
        "        'anchor': torch.zeros(1, device=device),\n",
        "        'leaf': torch.zeros(1, device=device),\n",
        "        'exists': torch.zeros(1, device=device),\n",
        "        'semantic': torch.zeros(1, device=device),\n",
        "        'edge_exists': torch.zeros(1, device=device),\n",
        "        'kldiv': torch.zeros(1, device=device),\n",
        "        'sym': torch.zeros(1, device=device),\n",
        "        'adj': torch.zeros(1, device=device)}\n",
        "\n",
        "    # process every data in the batch individually\n",
        "    for obj in objects:\n",
        "        obj.to(device)\n",
        "\n",
        "        # encode object to get root code\n",
        "        root_code = encoder.encode_structure(obj=obj)\n",
        "\n",
        "        # get kldiv loss\n",
        "        if not conf.non_variational:\n",
        "            root_code, obj_kldiv_loss = torch.chunk(root_code, 2, 1)\n",
        "            obj_kldiv_loss = -obj_kldiv_loss.sum() # negative kldiv, sum over feature dimensions\n",
        "            losses['kldiv'] = losses['kldiv'] + obj_kldiv_loss\n",
        "\n",
        "        # decode root code to get reconstruction loss\n",
        "        obj_losses = decoder.structure_recon_loss(z=root_code, gt_tree=obj)\n",
        "        for loss_name, loss in obj_losses.items():\n",
        "            losses[loss_name] = losses[loss_name] + loss\n",
        "\n",
        "    for loss_name in losses.keys():\n",
        "        losses[loss_name] = losses[loss_name] / len(objects)\n",
        "\n",
        "   # weighted sum\n",
        "    losses['box'] *= conf.loss_weight_box\n",
        "    losses['anchor'] *= conf.loss_weight_anchor\n",
        "    losses['leaf'] *= conf.loss_weight_leaf\n",
        "    losses['exists'] *= conf.loss_weight_exists\n",
        "    losses['semantic'] *= conf.loss_weight_semantic\n",
        "    losses['edge_exists'] *= conf.loss_weight_edge_exists\n",
        "    losses['kldiv'] *= conf.loss_weight_kldiv\n",
        "    losses['sym'] *= conf.loss_weight_sym\n",
        "    losses['adj'] *= conf.loss_weight_adj\n",
        "\n",
        "    total_loss = 0\n",
        "    for loss in losses.values():\n",
        "        total_loss += loss\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # log to console\n",
        "        if log_console:\n",
        "            print(\n",
        "                f'''{strftime(\"%H:%M:%S\", time.gmtime(time.time()-start_time)):>9s} '''\n",
        "                f'''{epoch:>5.0f}/{conf.epochs:<5.0f} '''\n",
        "                f'''{'validation' if is_valdt else 'training':^10s} '''\n",
        "                f'''{batch_ind:>5.0f}/{num_batch:<5.0f} '''\n",
        "                f'''{100. * (1+batch_ind+num_batch*epoch) / (num_batch*conf.epochs):>9.1f}%      '''\n",
        "                f'''{lr:>5.2E} '''\n",
        "                f'''{losses['box'].item():>11.2f} '''\n",
        "                f'''{(losses['leaf']+losses['exists']+losses['semantic']).item():>11.2f} '''\n",
        "                f'''{losses['edge_exists'].item():>11.2f} '''\n",
        "                f'''{losses['kldiv'].item():>10.2f} '''\n",
        "                f'''{losses['sym'].item():>10.2f} '''\n",
        "                f'''{losses['adj'].item():>10.2f} '''\n",
        "                f'''{losses['anchor'].item():>10.2f} '''\n",
        "                f'''{total_loss.item():>10.2f}''')\n",
        "            flog.write(\n",
        "                f'''{strftime(\"%H:%M:%S\", time.gmtime(time.time()-start_time)):>9s} '''\n",
        "                f'''{epoch:>5.0f}/{conf.epochs:<5.0f} '''\n",
        "                f'''{'validation' if is_valdt else 'training':^10s} '''\n",
        "                f'''{batch_ind:>5.0f}/{num_batch:<5.0f} '''\n",
        "                f'''{100. * (1+batch_ind+num_batch*epoch) / (num_batch*conf.epochs):>9.1f}%      '''\n",
        "                f'''{lr:>5.2E} '''\n",
        "                f'''{losses['box'].item():>11.2f} '''\n",
        "                f'''{(losses['leaf']+losses['exists']+losses['semantic']).item():>11.2f} '''\n",
        "                f'''{losses['edge_exists'].item():>11.2f} '''\n",
        "                f'''{losses['kldiv'].item():>10.2f} '''\n",
        "                f'''{losses['sym'].item():>10.2f} '''\n",
        "                f'''{losses['adj'].item():>10.2f} '''\n",
        "                f'''{losses['anchor'].item():>10.2f} '''\n",
        "                f'''{total_loss.item():>10.2f}\\n''')\n",
        "            flog.flush()\n",
        "\n",
        "        # log to tensorboard\n",
        "        if log_tb and tb_writer is not None:\n",
        "            tb_writer.add_scalar('loss', total_loss.item(), step)\n",
        "            tb_writer.add_scalar('lr', lr, step)\n",
        "            tb_writer.add_scalar('box_loss', losses['box'].item(), step)\n",
        "            tb_writer.add_scalar('anchor_loss', losses['anchor'].item(), step)\n",
        "            tb_writer.add_scalar('leaf_loss', losses['leaf'].item(), step)\n",
        "            tb_writer.add_scalar('exists_loss', losses['exists'].item(), step)\n",
        "            tb_writer.add_scalar('semantic_loss', losses['semantic'].item(), step)\n",
        "            tb_writer.add_scalar('edge_exists_loss', losses['edge_exists'].item(), step)\n",
        "            tb_writer.add_scalar('kldiv_loss', losses['kldiv'].item(), step)\n",
        "            tb_writer.add_scalar('sym_loss', losses['sym'].item(), step)\n",
        "            tb_writer.add_scalar('adj_loss', losses['adj'].item(), step)\n",
        "\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMacVY5jIeSq"
      },
      "source": [
        "## Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQBOU2pbyEQg"
      },
      "outputs": [],
      "source": [
        "def change_train_box_args(args):\n",
        "  args.exp_name = 'box_vae_pavilion_1020'\n",
        "  args.category = 'Pavilion'\n",
        "  args.data_path = './data/partnetdata/pavilion_hier1009'\n",
        "  args.train_dataset = 'train.txt'\n",
        "  args.val_dataset = 'val.txt'\n",
        "  args.epochs = 100\n",
        "  args.model_version = 'model_box'\n",
        "  args.max_child_num = 50\n",
        "  args.loss_weight_box = 23\n",
        "  args.checkpoint_interva = 50\n",
        "  return args\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A3Rdb-TIbPb"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "sys.setrecursionlimit(5000) # this code uses recursion a lot for code simplicity\n",
        "\n",
        "parser = ArgumentParser()\n",
        "parser = add_train_vae_args(parser)\n",
        "config,_ = parser.parse_known_args()\n",
        "config = change_train_box_args(config)\n",
        "\n",
        "\n",
        "Tree.load_category_info(config.category)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6VodctpQ7eT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc70c6d1-3e51-46d2-e8eb-f09d763cc9f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Object Category: Pavilion\n",
            "Random Seed: 3124256514\n",
            "Tree.num_sem in GNNChildEncoder: 11\n",
            "./data/models/box_vae_pavilion_1020\n",
            "encoder\n",
            "96_net_encoder.pth\n",
            "decoder\n",
            "96_net_decoder.pth\n",
            "Checkpoint 96_./data/models/box_vae_pavilion_1020/checkpt.pth not found for resuming, refine saved models instead? (y/n) y\n",
            "Checkpoint loaded. Resuming from epoch 97.\n",
            "Starting training ...... \n",
            "training run box_vae_pavilion_1020\n",
            "     Time    Epoch     Dataset    Iteration    Progress(%)       LR       BoxLoss   StructLoss   EdgeExists  KLDivLoss   SymLoss    AdjLoss  AnchorLoss  TotalLoss\n",
            " 00:00:27    97/100    training      0/22         97.0%      1.00E-03        4.93       13.88        1.14       2.22       0.27       0.12       1.61      24.17\n",
            "Saving checkpoint ...... DONE\n",
            " 00:00:59    97/100   validation     0/7          97.1%      1.00E-03        9.97       20.13        1.56       2.23       0.34       0.23       1.72      36.18\n",
            " 00:02:19    97/100    training      3/22         97.2%      1.00E-03        8.43       21.53        1.53       2.27       0.49       0.04       2.54      36.83\n",
            " 00:02:46    97/100   validation     1/7          97.3%      1.00E-03        8.76       20.99        1.56       1.70       0.33       0.09       2.50      35.93\n",
            " 00:04:02    97/100    training      6/22         97.3%      1.00E-03        6.40       17.32        1.20       1.92       0.23       0.13       2.38      29.57\n",
            " 00:04:28    97/100   validation     2/7          97.4%      1.00E-03        6.65       17.12        1.25       1.92       0.27       0.20       1.89      29.30\n",
            " 00:05:50    97/100    training      9/22         97.5%      1.00E-03        5.18       14.62        1.17       1.95       0.25       0.10       2.41      25.68\n",
            " 00:06:17    97/100   validation     3/7          97.6%      1.00E-03        6.65       17.52        1.23       1.72       0.28       0.11       2.21      29.71\n",
            "Saving checkpoint ...... DONE\n",
            " 00:07:39    97/100    training     12/22         97.6%      1.00E-03        6.30       15.72        1.22       1.67       0.21       0.19       2.38      27.68\n",
            " 00:08:08    97/100   validation     4/7          97.7%      1.00E-03        7.59       18.09        1.49       1.85       0.36       0.11       2.19      31.67\n",
            " 00:09:25    97/100    training     15/22         97.7%      1.00E-03        5.85       16.49        1.21       1.89       0.21       0.06       1.26      26.95\n",
            " 00:09:53    97/100   validation     5/7          97.9%      1.00E-03        6.33       15.91        0.86       1.66       0.11       0.10       3.25      28.22\n",
            " 00:11:09    97/100    training     18/22         97.9%      1.00E-03        6.19       16.56        1.02       2.04       0.20       0.13       2.51      28.65\n",
            " 00:11:16    97/100   validation     6/7          98.0%      1.00E-03        7.20       17.10        1.28       1.56       0.06       0.10       0.82      28.11\n",
            "Saving checkpoint ...... DONE\n",
            " 00:12:32    97/100    training     21/22         98.0%      1.00E-03        6.46       17.10        1.32       1.90       0.28       0.11       3.36      30.53\n",
            "training run box_vae_pavilion_1020\n",
            "     Time    Epoch     Dataset    Iteration    Progress(%)       LR       BoxLoss   StructLoss   EdgeExists  KLDivLoss   SymLoss    AdjLoss  AnchorLoss  TotalLoss\n",
            " 00:12:53    98/100   validation     0/7          98.1%      1.00E-03        7.04       19.87        1.35       1.73       0.38       0.08       2.01      32.46\n",
            " 00:13:10    98/100    training      2/22         98.1%      1.00E-03        6.74       17.18        1.04       1.93       0.16       0.15       2.37      29.56\n",
            " 00:13:28    98/100   validation     1/7          98.3%      1.00E-03        7.58       17.44        1.01       1.65       0.42       0.23       2.15      30.48\n",
            " 00:13:45    98/100    training      5/22         98.3%      1.00E-03        4.45       12.26        1.00       2.01       0.20       0.09       2.06      22.06\n",
            " 00:14:05    98/100   validation     2/7          98.4%      1.00E-03        6.83       16.09        1.04       1.90       0.28       0.09       2.82      29.05\n",
            " 00:14:25    98/100    training      8/22         98.4%      1.00E-03        6.22       19.58        1.23       2.01       0.32       0.11       1.52      30.99\n",
            "Saving checkpoint ...... DONE\n",
            " 00:14:43    98/100   validation     3/7          98.6%      1.00E-03        6.67       17.42        1.15       1.86       0.24       0.11       2.07      29.53\n",
            " 00:15:03    98/100    training     11/22         98.5%      1.00E-03        6.39       16.92        1.27       1.85       0.37       0.14       2.20      29.13\n",
            " 00:15:25    98/100   validation     4/7          98.7%      1.00E-03        7.14       17.95        1.62       2.17       0.34       0.15       2.43      31.80\n",
            " 00:15:43    98/100    training     14/22         98.7%      1.00E-03        6.72       17.66        1.23       1.96       0.39       0.12       3.15      31.23\n",
            " 00:16:05    98/100   validation     5/7          98.9%      1.00E-03        7.08       19.93        1.39       1.86       0.29       0.14       1.81      32.49\n",
            " 00:16:22    98/100    training     17/22         98.8%      1.00E-03        5.67       15.75        1.17       2.25       0.31       0.07       2.31      27.53\n",
            "Saving checkpoint ...... DONE\n",
            " 00:16:35    98/100   validation     6/7          99.0%      1.00E-03        7.05       16.27        1.25       1.59       0.25       0.04       3.96      30.40\n",
            " 00:16:54    98/100    training     20/22         99.0%      1.00E-03        6.86       18.23        1.29       2.03       0.30       0.14       2.26      31.11\n",
            "training run box_vae_pavilion_1020\n",
            "     Time    Epoch     Dataset    Iteration    Progress(%)       LR       BoxLoss   StructLoss   EdgeExists  KLDivLoss   SymLoss    AdjLoss  AnchorLoss  TotalLoss\n",
            " 00:17:22    99/100   validation     0/7          99.1%      1.00E-03        6.86       20.12        1.55       1.74       0.31       0.15       2.69      33.43\n",
            " 00:17:29    99/100    training      1/22         99.1%      1.00E-03        5.01       14.14        1.06       1.94       0.22       0.06       2.46      24.89\n",
            " 00:18:01    99/100   validation     1/7          99.3%      1.00E-03        7.53       21.05        1.79       1.64       0.56       0.21       4.16      36.94\n",
            " 00:18:08    99/100    training      4/22         99.2%      1.00E-03        5.51       13.33        1.20       1.94       0.28       0.08       2.90      25.23\n",
            "Saving checkpoint ...... DONE\n",
            " 00:18:41    99/100   validation     2/7          99.4%      1.00E-03        5.70       15.17        1.04       1.68       0.15       0.07       1.96      25.77\n",
            " 00:18:51    99/100    training      7/22         99.4%      1.00E-03        4.97       16.02        1.43       1.91       0.37       0.09       1.73      26.53\n",
            " 00:19:19    99/100   validation     3/7          99.6%      1.00E-03        6.43       18.83        1.05       1.65       0.23       0.13       2.01      30.32\n",
            " 00:19:28    99/100    training     10/22         99.5%      1.00E-03        5.90       17.53        1.38       2.14       0.31       0.15       1.55      28.94\n",
            " 00:19:56    99/100   validation     4/7          99.7%      1.00E-03        8.23       22.71        1.23       1.65       0.26       0.19       1.82      36.09\n",
            " 00:20:03    99/100    training     13/22         99.6%      1.00E-03        6.54       17.99        1.11       2.10       0.31       0.16       1.10      29.31\n",
            " 00:20:33    99/100   validation     5/7          99.9%      1.00E-03        6.67       15.28        1.21       2.25       0.34       0.08       1.92      27.75\n",
            " 00:20:40    99/100    training     16/22         99.8%      1.00E-03        6.35       19.09        1.22       1.93       0.31       0.14       2.15      31.19\n",
            "Saving checkpoint ...... DONE\n",
            " 00:21:04    99/100   validation     6/7         100.0%      1.00E-03        6.11       11.64        0.88       2.08       0.03       0.06       3.34      24.13\n",
            " 00:21:12    99/100    training     19/22         99.9%      1.00E-03        5.25       14.13        1.25       1.89       0.37       0.14       2.47      25.51\n",
            "Saving final checkpoint ...... DONE\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train(config,load_check=True,last_epoch=96)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p6bOE8QHNza"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMstMKA2Nmbo"
      },
      "source": [
        "##Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oxbAyAm4OOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7925c9e-8cb6-404b-80aa-d447f91a2fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.41.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm3GEteU5E-m"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5ollSVHNl7I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "dadf2984-e504-4663-9cbb-4038d4c197fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/box_vae_pavilion'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "src_dir = \"/content/drive/MyDrive/MIT Creative Machine Learning/Final Project/structurenet0503/data/logs/box_vae_pavilion_1020\"\n",
        "dst_dir = \"/content/box_vae_pavilion\"\n",
        "\n",
        "# Remove the destination directory if it already exists\n",
        "if os.path.exists(dst_dir):\n",
        "    shutil.rmtree(dst_dir)\n",
        "\n",
        "# Use shutil.copytree() to copy the entire directory\n",
        "shutil.copytree(src_dir, dst_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow"
      ],
      "metadata": {
        "id": "Wzs5QQspfnSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXQjUcjn13PX"
      },
      "outputs": [],
      "source": [
        "!kill 2655"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea79e2wp5-vO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1c0e43-c860-4d1b-c483-745cbf28b4a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GgdbjfeNqh3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "0be36d1b-6e3d-4c46-e632-a54dc71da7f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%tensorboard --logdir /content/box_vae_pavilion"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-_c2daYyAAUx",
        "7e8krzlYIo8p",
        "InsXaiYdJ8qT",
        "OFAa3SewDIAQ",
        "NPXxJ1ykXHcL",
        "OapezNE0Qpkr",
        "rApwVkccWVsT"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}